{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating IPFS and IPNS Systems\n",
    "\n",
    "This notebook provides a Python-based simulation of IPFS (InterPlanetary File System) and IPNS (InterPlanetary Naming System) to test various linking strategies for storing and retrieving IPAROs.\n",
    "\n",
    "The notebook uses three classes to simulate these systems:\n",
    "- **IPARO**: Represents the storage object on IPFS.\n",
    "- **IPNS**: Keeps track of the latest capture for different websites.\n",
    "- **IPFS**: Simulates the hashing, storage, and retrieval of IPARO objects.\n",
    "\n",
    "The goal of the simulation is to test various linking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "import hashlib\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPARO Object\n",
    "\n",
    "**Properties:**\n",
    "- `URL`: The capture URL.\n",
    "- `Timestamp`: The timestamp of the capture.\n",
    "- `Content`: The contents of the IPARO.\n",
    "\n",
    "**Functions:**\n",
    "- `__str__`: Returns a string representation of the IPARO object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class IPARO:\n",
    "    url: str\n",
    "    content: bytes\n",
    "    timestamp: datetime\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the IPARO object.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the URL and content of the IPARO.\n",
    "        \"\"\"\n",
    "        iparo = {\n",
    "            \"URL\": self.url,\n",
    "            \"Content\": self.content,\n",
    "            \"Timestamp\": self.timestamp,\n",
    "        }\n",
    "        return str(iparo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IPAROLink Object\n",
    "\n",
    "**Description:**\n",
    "\n",
    "- The IPAROLink class stores a link object, which will define links between two IPARO objects.\n",
    "- The source CID is used to lookup the IPARO objects, so only the target CIDs are recorded in the IPAROLink object.\n",
    "\n",
    "**Properties:**\n",
    "\n",
    "- `seq_num`: The sequence number of the link.\n",
    "- `timestamp`: The timestamp of the link.\n",
    "- `cid`: The CID of the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class IPAROLink:\n",
    "    \"\"\"\n",
    "    Defines the IPARO Link class that has a sequence number, a datetime, and a CID.\n",
    "    \"\"\"\n",
    "    seq_num: int\n",
    "    timestamp: datetime\n",
    "    cid: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IPAROLinkCollection Object\n",
    "\n",
    "**Description:**\n",
    "\n",
    "- The IPAROLinkCollection class stores all the links from a source node.\n",
    "- The source CID is used to lookup the IPARO objects, so only the target CIDs are recorded in the IPAROLink object.\n",
    "- The previous link has the maximum sequence number of all the links.\n",
    "    - This property must hold true since all strategies access the previous CID.\n",
    "    - The current node and all nodes afterwards have not been hashed before the creation of the link collection so it isn't possible for any node to have a higher sequence number.\n",
    "\n",
    "**Properties:**\n",
    "\n",
    "- `links`: The list of all links coming from the source IPARO.\n",
    "- `previous`: The link to the previous CID, which is the linked CID with the maximum sequence number.\n",
    "\n",
    "**Methods:**\n",
    "- `__str__`, `__repr__`: This should return the list of `IPAROLink` objects.\n",
    "- `__len__`: This should return the total number of links in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPAROLinkCollection:\n",
    "    \"\"\"\n",
    "    A helper class for linking IPAROs together. The two attributes are ``links`` (gets the links to other IPAROs)\n",
    "    and  ``previous`` (the previous IPAROLink).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, links: list[IPAROLink]):\n",
    "        \"\"\"\n",
    "        Initializes the collection of links on the IPARO object.\n",
    "\n",
    "        Args:\n",
    "            iparo (IPARO): The IPARO object to be linked.\n",
    "            links (list[IPAROLink]): The list of links to target IPAROs.\n",
    "        \"\"\"\n",
    "        self.links: list[IPAROLink] = links\n",
    "\n",
    "        # We are guaranteed that the previous node is in the list of links, and so would have the largest sequence number\n",
    "        self.previous: IPAROLink | None = max(links, key=lambda link: link.seq_num) if len(links) > 0 else None\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.links)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPNS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPNS class stores and maps the latest CID of a website.\n",
    "- Tracks the number of operations (get and update) performed.\n",
    "\n",
    "**Functions:**\n",
    "- `update`: Updates the latest CID of a website.\n",
    "- `get_cid`: Retrieves the CID of the latest capture for a website.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations.\n",
    "- `reset`: Resets the data.\n",
    "- `get_version_counts`: Get number of versions of a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPNS:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the IPNS object with an empty hashmap for storing CIDs\n",
    "        and counters for tracking operations.\n",
    "        \"\"\"\n",
    "        self.data: dict[str, str] = {}\n",
    "        self.version_counts: dict[str, int] = {}\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0\n",
    "\n",
    "    def update(self, url: str, cid: str):\n",
    "        \"\"\"\n",
    "        Updates the latest CID for a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "            cid (str): The CID of the latest capture.\n",
    "        \"\"\"\n",
    "        self.update_count += 1\n",
    "        self.data[url] = cid\n",
    "        self.version_counts[url] = self.version_counts.setdefault(url, 0) + 1\n",
    "\n",
    "    def get_cid(self, url: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the latest CID for a given URL if it exists, else None.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "\n",
    "        Returns:\n",
    "            str: The CID of the latest capture for the given URL if it exists, else None.\n",
    "        \"\"\"\n",
    "        self.get_count += 1\n",
    "        return self.data.get(url)\n",
    "\n",
    "    def get_number_of_nodes(self, url: str) -> int:\n",
    "        \"\"\"\n",
    "        Retrieves the number of nodes in a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of nodes for a given URL, or zero if the mapping is not present.\n",
    "        \"\"\"\n",
    "        return self.version_counts.get(url, 0)\n",
    "\n",
    "    def get_counts(self):\n",
    "        \"\"\"\n",
    "        Returns the number of update and get operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with the counts of update and get operations.\n",
    "        \"\"\"\n",
    "        return {\"get\": self.get_count, \"update\": self.update_count}\n",
    "\n",
    "    def reset_data(self):\n",
    "        \"\"\"\n",
    "        Resets the data.\n",
    "        \"\"\"\n",
    "        self.data: dict[str, str] = {}\n",
    "        self.version_counts: dict[str, int] = {}\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operating counts. Used for the evaluation phase.\n",
    "        \"\"\"\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Strategy Parameters\n",
    "\n",
    "**Description:** The LinkStrategyParams class is used to hold the parameters of a linking strategy that are usually needed for the LinkStrategy to properly work, without having to duplicate the code every time we create a linking strategy.\n",
    "\n",
    "**Properties:**\n",
    "- `url`: The URL, provided at the constructor level.\n",
    "- `latest_cid`: The latest CID, which is equal to the CID of the URL (note that this is different from the newly created IPARO object), if it exists.\n",
    "- `node_num`: The number of nodes created for the URL before the newly created IPARO object.\n",
    "- `latest_node`: The node with the latest CID. Used for accessing the timestamp.\n",
    "- `link`: The link to the latest node, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkStrategyParams:\n",
    "    \"\"\"\n",
    "    This class is designed to add parameters from the IPNS and the IPFS that are determined at runtime.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url: str):\n",
    "        self.url: str = url\n",
    "        self.latest_cid: str = ipns.get_cid(url)\n",
    "        self.node_num: int = ipns.get_number_of_nodes(url)\n",
    "        self.latest_node: Optional[IPARO] = ipfs.retrieve(self.latest_cid)\n",
    "        self.latest_node_links: list[IPAROLink] = ipfs.retrieve_links(self.latest_cid).links\n",
    "        self.link: Optional[IPAROLink] = IPAROLink(seq_num=self.node_num - 1,\n",
    "                                                   timestamp=self.latest_node.timestamp,\n",
    "                                                   cid=self.latest_cid) if self.latest_node is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Strategies\n",
    "**Description:**\n",
    "The LinkStrategy class encapsulates a linking strategy. This allows for more structure with regards to the approaches to evaluating them.\n",
    "\n",
    "**Functions:**\n",
    "\n",
    "- `get_linked_nodes`: Evaluate which IPARO nodes to link to, given the parameters for the linking strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkStrategy(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_linked_nodes(self, params: LinkStrategyParams) -> IPAROLinkCollection:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPFS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPFS class stores the nodes and simulates the hashing, storage, and retrieval operations.\n",
    "- Tracks the number of operations (hash, store, retrieve).\n",
    "\n",
    "**Functions:**\n",
    "- `hash`: Hashes the content of a node to generate its CID.\n",
    "- `link`: Links a node with other nodes using a linking strategy.\n",
    "- `store`: Stores a node with its CID.\n",
    "- `retrieve`: Retrieves a node using its CID.\n",
    "- `retrieve_links`: Retrieves the list of all links using the node's CID.\n",
    "- `retrieve_by_number`: Retrieves a node with a URL and its sequence number.\n",
    "- `retrieve_by_date`: Retrieves a node with a URL and its date, according to a given mode.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPFS:\n",
    "    \"\"\"\n",
    "    The InterPlanetary File System is responsible for hashing, storing,\n",
    "    retrieving, and linking IPARO objects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data: dict[str, IPARO] = {}\n",
    "        self.links: dict[str, IPAROLinkCollection] = {}\n",
    "        self.hash_count = 0\n",
    "        self.retrieve_count = 0\n",
    "        self.store_count = 0\n",
    "\n",
    "    def hash(self, iparo: IPARO) -> str:\n",
    "        \"\"\"\n",
    "        Hashes the IPARO to generate a CID.\n",
    "\n",
    "        Args:\n",
    "            iparo: IPARO: The IPARO object.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated CID.\n",
    "        \"\"\"\n",
    "        self.hash_count += 1\n",
    "        iparo_string = str(iparo)\n",
    "        sha256_hash = hashlib.sha256(iparo_string.encode()).hexdigest()\n",
    "        return 'Qm' + sha256_hash[:34]\n",
    "\n",
    "    def store(self, iparo: IPARO) -> str:\n",
    "        \"\"\"\n",
    "        Stores a node with its CID.\n",
    "\n",
    "        Args:\n",
    "            iparo (IPARO): The IPARO object to store.\n",
    "\n",
    "        Returns:\n",
    "            The CID of the newly stored IPARO.\n",
    "        \"\"\"\n",
    "        cid = self.hash(iparo)\n",
    "        self.store_count += 1\n",
    "        self.data[cid] = iparo\n",
    "        return cid\n",
    "\n",
    "    def link(self, cid: str, strategy: LinkStrategy, params: LinkStrategyParams) -> IPAROLinkCollection:\n",
    "        \"\"\"\n",
    "        Links an IPARO with the specified CID to other IPAROs, according to the provided linking strategy.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the IPARO object.\n",
    "            strategy (LinkStrategy): The link strategy to use when linking to other IPAROs.\n",
    "            params (LinkStrategyParams): The parameters for the linking strategy.\n",
    "\n",
    "        Returns:\n",
    "            IPAROLinkCollection: The links added for the newly created node.\n",
    "        \"\"\"\n",
    "        links = strategy.get_linked_nodes(params)\n",
    "        self.links[cid] = links\n",
    "        return links\n",
    "\n",
    "    def reset_data(self):\n",
    "        \"\"\"\n",
    "        Resets the data for the IPFS.\n",
    "        \"\"\"\n",
    "        self.data: dict[str, IPARO] = {}\n",
    "        self.links: dict[str, IPAROLinkCollection] = {}\n",
    "\n",
    "    def retrieve(self, cid) -> Optional[IPARO]:\n",
    "        \"\"\"\n",
    "        Retrieves the IPARO object corresponding to a given CID, if it exists, otherwise, ``None``.\n",
    "        \"\"\"\n",
    "        self.retrieve_count += 1\n",
    "        return self.data.get(cid)\n",
    "\n",
    "    def retrieve_links(self, cid: str) -> IPAROLinkCollection:\n",
    "        \"\"\"\n",
    "        Retrieves the IPARO links corresponding to a given CID. Does not count as an IPARO operation for\n",
    "        the purposes of evaluation.\n",
    "        \"\"\"\n",
    "        return self.links.get(cid, IPAROLinkCollection([]))\n",
    "\n",
    "    def retrieve_by_timestamp(self, url: str, target_timestamp: datetime, mode: Mode = Mode.LATEST_BEFORE) -> \\\n",
    "            Optional[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the IPARO versions of a given URL closest to a given datetime if at least one\n",
    "        IPARO version is stored in the IPFS, otherwise ``None``. Default is the latest timestamp\n",
    "        that occurs before the target timestamp, but ``Mode.EARLIEST_AFTER`` gives the node with\n",
    "        the earliest time after a given timestamp, and ``Mode.CLOSEST`` gives the node with the\n",
    "        closest timestamp to a given timestamp. If the distance from the two closest times to\n",
    "        the target timetamp are equal, the CID with the earlier timestamp will be chosen.\n",
    "        \"\"\"\n",
    "        self.retrieve_count += 1\n",
    "\n",
    "        timestamps = sorted((iparo.timestamp, cid) for cid, iparo in self.data.items() if iparo.url == url)\n",
    "\n",
    "        # Early exit\n",
    "        if len(timestamps) == 0:\n",
    "            return None\n",
    "\n",
    "        timestamp: Optional[datetime]\n",
    "        if mode == Mode.LATEST_BEFORE:\n",
    "            timestamps = [t for t in timestamps if t[0] <= target_timestamp]\n",
    "            _, cid = min(timestamps, default=None, key=lambda ts: target_timestamp - ts[0])\n",
    "        elif mode == Mode.CLOSEST:\n",
    "            # Find the key with the minimum difference to the target timestamps\n",
    "            _, cid = min(timestamps, default=None, key=lambda ts: abs(ts[0] - target_timestamp))\n",
    "        else:\n",
    "            timestamps = [t for t in timestamps if t[0] >= target_timestamp]\n",
    "            _, cid = min(timestamps, default=None, key=lambda ts: ts[0] - target_timestamp)\n",
    "\n",
    "        return cid\n",
    "\n",
    "    def retrieve_by_number(self, url: str, number: int) -> str:\n",
    "        \"\"\"\n",
    "        Retrieves the IPARO CID corresponding to a given sequence number and a URL.\n",
    "        \"\"\"\n",
    "        cid = ipns.get_cid(url)\n",
    "        num_nodes = ipns.get_number_of_nodes(url)\n",
    "        self.retrieve_count += 1\n",
    "        for i in range(number, num_nodes - 1):\n",
    "            links = self.retrieve_links(cid)\n",
    "            cid = links.previous.cid\n",
    "        return cid\n",
    "\n",
    "    def get_counts(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns the number of hash, store, and retrieve operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with counts of hash, store, and retrieve operations.\n",
    "        \"\"\"\n",
    "        counts = {\"hash\": self.hash_count, \"store\": self.store_count,\n",
    "                  \"retrieve\": self.retrieve_count}\n",
    "        return counts\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operation counters.\n",
    "        \"\"\"\n",
    "        self.hash_count = 0\n",
    "        self.store_count = 0\n",
    "        self.retrieve_count = 0\n",
    "\n",
    "    def get_all_cids(self, url: str) -> tuple[list[str], list[IPARO]]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of all CIDs and IPAROs in the IPFS, corresponding to the given URL.\n",
    "        The nodes are sorted from latest to earliest.\n",
    "        \"\"\"\n",
    "        cids = []\n",
    "        iparos = []\n",
    "        cid = ipns.get_cid(url)\n",
    "        while True:\n",
    "            if cid is not None:\n",
    "                cids.append(cid)\n",
    "                iparo = self.retrieve(cid)\n",
    "                if iparo is not None:\n",
    "                    iparos.append(iparo)\n",
    "            links = self.retrieve_links(cid)\n",
    "            if links is None or links.previous is None:\n",
    "                break\n",
    "            cid = links.previous.cid\n",
    "\n",
    "        return cids, iparos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPAROFactory\n",
    "\n",
    "The purpose of the IPAROFactory class is to create IPARO nodes. In particular, we will have this method:\n",
    "\n",
    "- `create_node`: A method that takes in two arguments and creates an IPARO object out of the URL and the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPAROFactory:\n",
    "    @classmethod\n",
    "    def create_node(cls, url: str, content: bytes) -> IPARO:\n",
    "        \"\"\"\n",
    "        Creates an IPARO object.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the IPARO object.\n",
    "            content (bytes): The contents of the IPARO object.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        iparo = IPARO(url=url, content=content, timestamp=timestamp)\n",
    "        return iparo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Operation Tracking\n",
    "\n",
    "Here, we initialize the IPFS and IPNS objects and define a helper function `get_op_counts()` to display the number of operations performed. Additionally, the `initialize()` operation sets up those objects and the `automate_node_creation()` function takes in a URL, a number of nodes, and a `LinkStrategy` and returns a list of IPARO objects to debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    '''\n",
    "    Initializes the simulated IPFS and IPNS.\n",
    "\n",
    "    (This function should be in a separate file, but for the sake of simplicity, it is included here.)\n",
    "    '''\n",
    "    global ipfs, ipns, iparo_factory\n",
    "    ipfs = IPFS()\n",
    "    ipns = IPNS()\n",
    "    iparo_factory = IPAROFactory()\n",
    "\n",
    "# # Initializing the simulated IPFS and IPNS\n",
    "# ipfs = IPFS()\n",
    "# ipns = IPNS()\n",
    "\n",
    "def get_op_counts():\n",
    "    '''\n",
    "    Displays the number of operations performed by IPNS and IPFS.\n",
    "    '''\n",
    "    print(\"Number of operations IPNS performed:\")\n",
    "    print(ipns.get_counts())\n",
    "    print(\"Number of operations IPFS performed:\")\n",
    "    print(ipfs.get_counts())\n",
    "\n",
    "def setup():\n",
    "    '''\n",
    "    Sets up the testing environment for the different linking strategies.\n",
    "    '''\n",
    "    ipns.reset_data()\n",
    "    ipns.reset_counts()\n",
    "    ipfs.reset_data()\n",
    "    ipfs.reset_counts()\n",
    "\n",
    "\n",
    "def test_storage_strategy(strategy: LinkStrategy, url: str, node_num: int):\n",
    "    setup()\n",
    "    # Automate the creation of additional nodes\n",
    "    nodes = []\n",
    "    for i in range(100):\n",
    "        content = f\"Node {i}\"\n",
    "        iparo = IPAROFactory.create_node(URL, content)\n",
    "        cid = ipfs.store(iparo)\n",
    "        params = LinkStrategyParams(URL)\n",
    "        link_col = ipfs.link(cid, strategy, params)\n",
    "        ipns.update(URL, cid)\n",
    "        time.sleep(0.01)\n",
    "    get_op_counts()  # Output operation counts\n",
    "    \n",
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Linking Strategies\n",
    "\n",
    "### 1. Linking to Only the Previous Node\n",
    "\n",
    "In this test, each node will link only to the previous node in the chain. This strategy will be used to simulate a simple sequential storage system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleStrategy(LinkStrategy):\n",
    "\n",
    "    def get_linked_nodes(self, params: LinkStrategyParams) -> IPAROLinkCollection:\n",
    "        links = [params.link] if params.latest_node is not None else []\n",
    "        return IPAROLinkCollection(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 100}\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.example.com/\"\n",
    "NODE_NUM = 100\n",
    "test_storage_strategy(SingleStrategy(), URL, NODE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding a `LinkStrategy` class and a method to store all the nodes, we managed to cut down the number of lines of code to 3. How awesome is that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 51\n",
      "Node: {'URL': 'https://www.example.com/', 'Content': 'Node 99', 'Timestamp': datetime.datetime(2025, 2, 11, 20, 58, 19, 90924)}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 1}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipns.reset_counts()\n",
    "ipfs.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "cid = latest_node_cid\n",
    "links = ipfs.retrieve_links(cid).links\n",
    "while node.content != node.target_content and len(links) > 0:\n",
    "    links = ipfs.retrieve_links(cid).links\n",
    "    node == 2\n",
    "\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linking to all previous nodes\n",
    "\n",
    "In this test, each node will link to all the previous nodes in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveStrategy(LinkStrategy):\n",
    "\n",
    "    def get_linked_nodes(self, params: LinkStrategyParams) -> IPAROLinkCollection:\n",
    "        cids, iparos = ipfs.get_all_cids(params.url)\n",
    "        n = len(cids)\n",
    "        return IPAROLinkCollection([IPAROLink(timestamp=iparo.timestamp,\n",
    "                                              seq_num=n - i - 1,\n",
    "                                              cid=cid) for i, (cid, iparo) in enumerate(zip(cids, iparos))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IPARO.__init__() got an unexpected keyword argument 'cid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m to_be_hashed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m({\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: timestamp\n\u001b[0;32m     14\u001b[0m })\n\u001b[0;32m     15\u001b[0m cid \u001b[38;5;241m=\u001b[39m ipfs\u001b[38;5;241m.\u001b[39mhash(to_be_hashed)\n\u001b[1;32m---> 16\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[43mIPARO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinked_cids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m ipfs\u001b[38;5;241m.\u001b[39mstore(cid, first_node)\n\u001b[0;32m     19\u001b[0m ipns\u001b[38;5;241m.\u001b[39mupdate(URL, cid)\n",
      "\u001b[1;31mTypeError\u001b[0m: IPARO.__init__() got an unexpected keyword argument 'cid'"
     ]
    }
   ],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "first_node = IPAROFactory.create_node(url=URL, content=content)\n",
    "cid = ipfs.store(first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipfs.link(cid, SingleStrategy())\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, there are 2 ways of creating a new node for this linking strategy, since this is a simulation, no data corruption can happen but that might not be true in practice. When retrieving the latest node which should contain the CIDs of all the previous node, two scenarios can happen:\n",
    "1. The data is intact and the CIDs in the list is \"correct\" (which we really can't know for sure) and we can just add it to the new node we're creating\n",
    "2. The data is corrupt and one or more of the CIDs is wrong or unfinished, in which case we have to recheck every CID to rebuild a new list of linked CIDs (not to mention fixing all the corrupted nodes)\n",
    "\n",
    "So, for the purpose of this simulation, we will perform a check for every CID in the linked CID list of an IPARO to simulate the worst case scenario every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 0, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 0}\n"
     ]
    }
   ],
   "source": [
    "    def get_linked_nodes(self, params: LinkStrategyParams) -> IPAROLinkCollection:\n",
    "        cids, iparos = ipfs.get_all_cids(params.url)\n",
    "        n = len(cids)\n",
    "        return IPAROLinkCollection([IPAROLink(timestamp=iparo.timestamp,\n",
    "                                              seq_num=n - i - 1,\n",
    "                                              cid=cid) for i, (cid, iparo) in enumerate(zip(cids, iparos))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worst case scenario, where we have to retrieve and verify every CIDs in the linked CIDs of an IPARO, the retrieve count goes to almost 5000 (if we're storing 100 nodes)\\\n",
    "Of course this trade off makes it really easy to navigate to all the nodes just from the latest nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 60\n",
      "Found node: {'CID': 'Qm1da1654734bcd4c1916abecb53187078a0', 'Content': 'Node 60', 'Linked CID(s)': ['Qm87e94bd507c616d1722ff02dd064c75f07', 'Qm252912dc39ee661294bbeb314735696322', 'Qm85fff761585c14ca022e3cb5ef98bd5b53', 'Qmd819950d6e7f6ff0ae2cd8fbb2eb4f43fc', 'Qm028bf8e8b2db4872aec23e70769408f7de', 'Qmdbe64536d592c6d25aeb2ac0b33471bc34', 'Qme691d3791804c55ac5eb274500224cd399', 'Qm00ad1ba47942cacf117a518af3e7bab22c', 'Qm3d896f5e7c6e56b786f74729bc00b1757b', 'Qm4b3af7388608379f5159b11923e17d8f63', 'Qm49fec5db675584fea5647b927603d283ff', 'Qm2c0b84269832a02e83d101648515340bf4', 'Qm42d798dd864b6b8f28270e76341206f164', 'Qm4683fb47cc9a69f84b82122a60fff9200e', 'Qm3289b0cedae6d96b6aafbe38bfe672932b', 'Qm7aabef6d02221b0930a0ff9cf72dc3cbcb', 'Qm926210aeb5e482cdb64971669029ef9c4f', 'Qm304c8f8dabf8ea5a85e9cc5547d32a2373', 'Qm35cf86b224bb43b71c4cbd36c1ab2f08b8', 'Qm45e64c5fbb3cb9416fcdb9ee2062308faa', 'Qm2af12ba3fe8961a200f6787282780d1cd3', 'Qme466eab1165dde68335ad381cc0fb089ce', 'Qm194e0b1d1afaca092c4f1410f43346e215', 'Qm8ecaedf7799b043221c64a297a6cfd5de2', 'Qma9a3faaff350b5ce09f71087a8ad47c790', 'Qma62a1dd698aee15efa0c72861878cce729', 'Qmfd7039282116a6a61e5883b42f2824228c', 'Qm630b9781a2cdad03769e3289cd93d9edcd', 'Qm3283b473fea5b96fcabd846308e3a453c5', 'Qmdaa75b13bff6ae3b13aebb1920404c277a', 'Qm2f189c580f443e0470987d1b3b7d1c1507', 'Qm580b6ba5fc9f1b0e9759ebd20e28a7e639', 'Qm95c53e8d3f2879db8c165bd6f42c45745f', 'Qm8f77f96d74e7148e114045189776c6dbd4', 'Qmc1094d29c0d050c7477151829cd140c3c3', 'Qm3fdd2acb60957da80966296aace937e15a', 'Qm7f2142a907c8ef1e80e1d4a84042952fcb', 'Qm81388b2b1d91eba28e2e1674180c90d441', 'Qmdb50f5150c4a9a680585c7d67fd29d111f', 'Qm09483e13e1d5f496121bbe4ad3f5d23076', 'Qmfb242f1b3477bf4691c86b86077807eb69', 'Qmd80ec93f83af2d27325ef6bdd0560b7135', 'Qmcf366be4063f6a18ccca0010d66a41d2fd', 'Qm74792de93c42ee01b49401338ae83e131c', 'Qm2646e2c0f38cdde2aefd72d62b9827ab9f', 'Qmba90685535a0218535acae4e081f3ed4a9', 'Qm40f5c6b225c61b7490d353aef8db650d41', 'Qm1422e9aadfc6bf39a47b095a95b7e2a5ab', 'Qma850519421f754ea14ccb4b5a405f84bc8', 'Qm69c1f2af1cf2f67701d98a3f07ad56515e', 'Qme8ce694bfa792fd8271aa40a870df62b4e', 'Qm93b93782bb027b411899495eda037a16d7', 'Qmaee5d77258bdc9efa958c5fc350df04c57', 'Qm51d3a67d13666f56870f0e524fa1846d10', 'Qm96173a156e4e3bb6a99ee6921665df308c', 'Qm3e21a4fd477ffe159eb9b0cee8fa3bd8b5', 'Qmd933b04d67888be6c66e67a18cd10cd52c', 'Qm1a4396a01480e0e4deea618efc8a79a5f8', 'Qmd3620ff4e2eb5327dd6b4c308aec62dbe7', 'Qm184a1a5fe0811e26748e83834033992914', 'Qm1da1654734bcd4c1916abecb53187078a0', 'Qm3fb72eb9fbc7991068e67e0136b6584505', 'Qmb0f50ad0b6be7ee259a07d88829aac3bd2', 'Qm9d1b04875af8e7c65050c479a1b6a78b1e', 'Qm45a514ccf594621575a552599eaecd5a8d', 'Qmebf81166ed1a5890256faa042e9a97ac6d', 'Qmc26908ff139740d58d99646dd7651513d3', 'Qm9d39d76e1f1c1f71f1fdb424d678119b98', 'Qm2fe0914337d2c6a74449c36b0adfa86617', 'Qm28b080ad121f969960e6d2a62a293cce6f', 'Qmb9b29856da3fcfc4b5003bb337ddfd17d4', 'Qmcd17a232752d8c89b677fc6a8ff034c47d', 'Qm9fa3142705de81d5e5a0dc2ceba7b57b43', 'Qm5366e6f2bb50af80e103ca0fb1678a0c27', 'Qm7f22de597b5a873ab61c931eae68e9a68d', 'Qme6562acddb42b9f96b4eb5b96552641565', 'Qmade39767ff82d6448ec98cdd0f89d3b3a4', 'Qm0a04b3cbd23d0470bb5b32fcbe498a8fb5', 'Qma928b1ee840384379b4c0f27529f697cc1', 'Qmbd5cb855acd2b0bb5d42915b7cd8fed2d7', 'Qm85ce6603f10e75f89ad0725650f41ae726', 'Qm43a131dd8c4a22377266f8a3bde9f68c1b', 'Qmc894bd23728c00bd4b6184810f894eb230', 'Qm9a9626a42f352fe3c7268eb4809aa42544', 'Qm906d339fcc2a5071318d27449cddd9d846', 'Qmd0e9139cd0c151213c26a44aa62088b6df', 'Qm0ac3b3c247dccdd1e22f1b9ba15262c662', 'Qm20222416e9488d4c8d62750b12bb8cd792', 'Qmf3b621bb93facc4f8468052ea6d397ee20', 'Qm4633865b906e848c3114aa4c4e0fed34fa', 'Qm6c700fe50fc599bd89c6ab3cc0959c27ec', 'Qm8bc12d59db4b9f4446994fd88339a18d2a', 'Qm983d8fce7e3f041094f9026b3734615070', 'Qm4402817f14e1943a72a51c999fd4b0cc21', 'Qm18aef7a277c85bd8a1f36753180d1b1993', 'Qmdf1edf36f17586ba40eddcb00f384fe6ae', 'Qm73c25163c9c8959edd19f49909725a0b78', 'Qm8ac4bffa8646c1d35c9f9c3b1cec55c5f4', 'Qmcff5601d6a0e4581196e28eba08f0d803f'], 'Timestamp': 1737586700.193887}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 62}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "for linked_cid in linked_cids:\n",
    "    node = ipfs.retrieve(linked_cid)\n",
    "    if node.content == target_content:\n",
    "        break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linking to previous and first node\n",
    "\n",
    "In this test, each node will link to the previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 160}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    linked_cids = []\n",
    "    latest_node_linked_cids = latest_node.linked_cids\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 43\n",
      "Found node: {'CID': 'Qmc5a1d37f984ab18bb1ac81dab2965af48c', 'Content': 'Node 43', 'Linked CID(s)': ['Qm6d875a687a6fe84af3f690e499a362c675', 'Qmcd7ab5bb680959cb249e5f9ee094d940b3'], 'Timestamp': 1737586700.2084281}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 58}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.content == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    while True:\n",
    "        node = ipfs.retrieve(linked_cids[1])\n",
    "        linked_cids = node.linked_cids\n",
    "        if node.content == target_content:\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linking to K-previous and first node\n",
    "\n",
    "In this test, each node will link to K previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "K = 5\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 156}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.linked_cids\n",
    "    linked_cids = []\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    if len(latest_node_linked_cids) == K+1:\n",
    "        linked_cids.extend(latest_node_linked_cids[2:])\n",
    "    else:\n",
    "        linked_cids.extend(latest_node_linked_cids[1:])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 61\n",
      "Found node: {'CID': 'Qme8ee85530047974dd6fce81f94f7eb61e1', 'Content': 'Node 61', 'Linked CID(s)': ['Qm7002299cee28720f7f6610a5deef274c72', 'Qm035b891928734dcc4e958d10b72c64f155', 'Qme3404c45ce32b2cae3e52802048f287bd0', 'Qm7a116eda93546b04ed5b5da93206324156', 'Qmac3ec569cd2fe5b69f471e9dd4efe1ce0d', 'Qmaeb8a331a50728c73f59bff02269bde370'], 'Timestamp': 1737586700.223305}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 48}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.content == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.content == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index 1\n",
    "    node = ipfs.retrieve(linked_cids[1])\n",
    "    linked_cids = node.linked_cids\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.content == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[1])\n",
    "            linked_cids = node.linked_cids\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Linking to K-random and first node\n",
    "\n",
    "In this test, each node will link to a random K previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IPARO.__init__() got an unexpected keyword argument 'cid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m to_be_hashed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m({\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: timestamp\n\u001b[0;32m     18\u001b[0m })\n\u001b[0;32m     19\u001b[0m cid \u001b[38;5;241m=\u001b[39m ipfs\u001b[38;5;241m.\u001b[39mhash(to_be_hashed)\n\u001b[1;32m---> 20\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[43mIPARO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinked_cids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m ipfs\u001b[38;5;241m.\u001b[39mstore(cid, first_node)\n\u001b[0;32m     23\u001b[0m ipns\u001b[38;5;241m.\u001b[39mupdate(URL, cid)\n",
      "\u001b[1;31mTypeError\u001b[0m: IPARO.__init__() got an unexpected keyword argument 'cid'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 30\n",
    "URL = \"example.com\"\n",
    "Kmin = 5\n",
    "Kmax = 10\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.linked_cids\n",
    "    linked_cids = []\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    K = random.randint(Kmin, Kmax)\n",
    "    # Check if the number of linked CIDs is greater than K and add K-1 random linked CIDs\n",
    "    if len(latest_node_linked_cids) > K:\n",
    "        linked_cids.extend(random.sample(latest_node_linked_cids[1:], K-1))\n",
    "    # If the number of linked CIDs is less than K add all the linked CIDs\n",
    "    else:\n",
    "        linked_cids.extend(latest_node_linked_cids[1:])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    print(\"K = \", K+1)\n",
    "    print(\"Length of linked_cids: \", len(linked_cids))\n",
    "    print(node)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 9\n",
      "Can't find node\n",
      "Found node: {'CID': 'Qm1e263465f816c6b18846d14a7560ad48a9', 'Content': 'Node 1', 'Linked CID(s)': ['Qm58bc5abb4e0ae4b7b18942a800381e293d'], 'Timestamp': 1737586700.235092}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 41}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.content == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.content == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index 1\n",
    "    node = ipfs.retrieve(linked_cids[1])\n",
    "    linked_cids = node.linked_cids\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.content == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[1])\n",
    "            linked_cids = node.linked_cids\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking to Sequential Exponential (Base K, K an integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2\n",
      "Node 1\n",
      "Node 0\n",
      "Length of linked_cids:  2\n",
      "Node 3\n",
      "Node 2\n",
      "Node 1\n",
      "Length of linked_cids:  3\n",
      "Node 4\n",
      "Node 3\n",
      "Node 2\n",
      "Node 0\n",
      "Length of linked_cids:  3\n",
      "Node 5\n",
      "Node 4\n",
      "Node 3\n",
      "Node 1\n",
      "Length of linked_cids:  4\n",
      "Node 6\n",
      "Node 5\n",
      "Node 4\n",
      "Node 2\n",
      "Length of linked_cids:  4\n",
      "Node 7\n",
      "Node 6\n",
      "Node 5\n",
      "Node 3\n",
      "Node 0\n",
      "Length of linked_cids:  4\n",
      "Node 8\n",
      "Node 7\n",
      "Node 6\n",
      "Node 4\n",
      "Node 0\n",
      "Length of linked_cids:  4\n",
      "Node 9\n",
      "Node 8\n",
      "Node 7\n",
      "Node 5\n",
      "Node 1\n",
      "Length of linked_cids:  5\n",
      "Node 10\n",
      "Node 9\n",
      "Node 8\n",
      "Node 6\n",
      "Node 2\n",
      "Length of linked_cids:  5\n",
      "Node 11\n",
      "Node 10\n",
      "Node 9\n",
      "Node 7\n",
      "Node 3\n",
      "Length of linked_cids:  5\n",
      "Node 12\n",
      "Node 11\n",
      "Node 10\n",
      "Node 8\n",
      "Node 4\n",
      "Length of linked_cids:  5\n",
      "Node 13\n",
      "Node 12\n",
      "Node 11\n",
      "Node 9\n",
      "Node 5\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 14\n",
      "Node 13\n",
      "Node 12\n",
      "Node 10\n",
      "Node 6\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 15\n",
      "Node 14\n",
      "Node 13\n",
      "Node 11\n",
      "Node 7\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 16\n",
      "Node 15\n",
      "Node 14\n",
      "Node 12\n",
      "Node 8\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 17\n",
      "Node 16\n",
      "Node 15\n",
      "Node 13\n",
      "Node 9\n",
      "Node 1\n",
      "Length of linked_cids:  6\n",
      "Node 18\n",
      "Node 17\n",
      "Node 16\n",
      "Node 14\n",
      "Node 10\n",
      "Node 2\n",
      "Length of linked_cids:  6\n",
      "Node 19\n",
      "Node 18\n",
      "Node 17\n",
      "Node 15\n",
      "Node 11\n",
      "Node 3\n",
      "Length of linked_cids:  6\n",
      "Node 20\n",
      "Node 19\n",
      "Node 18\n",
      "Node 16\n",
      "Node 12\n",
      "Node 4\n",
      "Length of linked_cids:  6\n",
      "Node 21\n",
      "Node 20\n",
      "Node 19\n",
      "Node 17\n",
      "Node 13\n",
      "Node 5\n",
      "Length of linked_cids:  6\n",
      "Node 22\n",
      "Node 21\n",
      "Node 20\n",
      "Node 18\n",
      "Node 14\n",
      "Node 6\n",
      "Length of linked_cids:  6\n",
      "Node 23\n",
      "Node 22\n",
      "Node 21\n",
      "Node 19\n",
      "Node 15\n",
      "Node 7\n",
      "Length of linked_cids:  6\n",
      "Node 24\n",
      "Node 23\n",
      "Node 22\n",
      "Node 20\n",
      "Node 16\n",
      "Node 8\n",
      "Length of linked_cids:  6\n",
      "Node 25\n",
      "Node 24\n",
      "Node 23\n",
      "Node 21\n",
      "Node 17\n",
      "Node 9\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 26\n",
      "Node 25\n",
      "Node 24\n",
      "Node 22\n",
      "Node 18\n",
      "Node 10\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 27\n",
      "Node 26\n",
      "Node 25\n",
      "Node 23\n",
      "Node 19\n",
      "Node 11\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 28\n",
      "Node 27\n",
      "Node 26\n",
      "Node 24\n",
      "Node 20\n",
      "Node 12\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 29\n",
      "Node 28\n",
      "Node 27\n",
      "Node 25\n",
      "Node 21\n",
      "Node 13\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 30\n",
      "Node 29\n",
      "Node 28\n",
      "Node 26\n",
      "Node 22\n",
      "Node 14\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 31\n",
      "Node 30\n",
      "Node 29\n",
      "Node 27\n",
      "Node 23\n",
      "Node 15\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 32\n",
      "Node 31\n",
      "Node 30\n",
      "Node 28\n",
      "Node 24\n",
      "Node 16\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 33\n",
      "Node 32\n",
      "Node 31\n",
      "Node 29\n",
      "Node 25\n",
      "Node 17\n",
      "Node 1\n",
      "Length of linked_cids:  7\n",
      "Node 34\n",
      "Node 33\n",
      "Node 32\n",
      "Node 30\n",
      "Node 26\n",
      "Node 18\n",
      "Node 2\n",
      "Length of linked_cids:  7\n",
      "Node 35\n",
      "Node 34\n",
      "Node 33\n",
      "Node 31\n",
      "Node 27\n",
      "Node 19\n",
      "Node 3\n",
      "Length of linked_cids:  7\n",
      "Node 36\n",
      "Node 35\n",
      "Node 34\n",
      "Node 32\n",
      "Node 28\n",
      "Node 20\n",
      "Node 4\n",
      "Length of linked_cids:  7\n",
      "Node 37\n",
      "Node 36\n",
      "Node 35\n",
      "Node 33\n",
      "Node 29\n",
      "Node 21\n",
      "Node 5\n",
      "Length of linked_cids:  7\n",
      "Node 38\n",
      "Node 37\n",
      "Node 36\n",
      "Node 34\n",
      "Node 30\n",
      "Node 22\n",
      "Node 6\n",
      "Length of linked_cids:  7\n",
      "Node 39\n",
      "Node 38\n",
      "Node 37\n",
      "Node 35\n",
      "Node 31\n",
      "Node 23\n",
      "Node 7\n",
      "Length of linked_cids:  7\n",
      "Node 40\n",
      "Node 39\n",
      "Node 38\n",
      "Node 36\n",
      "Node 32\n",
      "Node 24\n",
      "Node 8\n",
      "Length of linked_cids:  7\n",
      "Node 41\n",
      "Node 40\n",
      "Node 39\n",
      "Node 37\n",
      "Node 33\n",
      "Node 25\n",
      "Node 9\n",
      "Length of linked_cids:  7\n",
      "Node 42\n",
      "Node 41\n",
      "Node 40\n",
      "Node 38\n",
      "Node 34\n",
      "Node 26\n",
      "Node 10\n",
      "Length of linked_cids:  7\n",
      "Node 43\n",
      "Node 42\n",
      "Node 41\n",
      "Node 39\n",
      "Node 35\n",
      "Node 27\n",
      "Node 11\n",
      "Length of linked_cids:  7\n",
      "Node 44\n",
      "Node 43\n",
      "Node 42\n",
      "Node 40\n",
      "Node 36\n",
      "Node 28\n",
      "Node 12\n",
      "Length of linked_cids:  7\n",
      "Node 45\n",
      "Node 44\n",
      "Node 43\n",
      "Node 41\n",
      "Node 37\n",
      "Node 29\n",
      "Node 13\n",
      "Length of linked_cids:  7\n",
      "Node 46\n",
      "Node 45\n",
      "Node 44\n",
      "Node 42\n",
      "Node 38\n",
      "Node 30\n",
      "Node 14\n",
      "Length of linked_cids:  7\n",
      "Node 47\n",
      "Node 46\n",
      "Node 45\n",
      "Node 43\n",
      "Node 39\n",
      "Node 31\n",
      "Node 15\n",
      "Length of linked_cids:  7\n",
      "Node 48\n",
      "Node 47\n",
      "Node 46\n",
      "Node 44\n",
      "Node 40\n",
      "Node 32\n",
      "Node 16\n",
      "Length of linked_cids:  7\n",
      "Node 49\n",
      "Node 48\n",
      "Node 47\n",
      "Node 45\n",
      "Node 41\n",
      "Node 33\n",
      "Node 17\n",
      "Node 0\n",
      "Length of linked_cids:  7\n",
      "Number of operations IPNS performed:\n",
      "{'get': 50, 'update': 50}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 50, 'store': 50, 'retrieve': 289}\n"
     ]
    }
   ],
   "source": [
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 50\n",
    "K = 2\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \" + str(i)\n",
    "    print(content)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.linked_cids\n",
    "    linked_cids = []\n",
    "\n",
    "    # Link to previous node FIRST\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    cids = []\n",
    "\n",
    "    j = 1\n",
    "    # Temp node = latest node CID inserted (before this one). Call that node K-1.\n",
    "    if i == 4:\n",
    "        pass\n",
    "    temp_node = latest_node\n",
    "    print(temp_node.content)\n",
    "    done = False\n",
    "    while True:\n",
    "        # Theorem: For any m < len(temp_node_linked_cids), the (1+m)th-to-last position of the linked CIDs list will link\n",
    "        # K^m nodes away from the node.\n",
    "        # Base Case: The previous node always gets assigned the last position (m=0), so the base case holds.\n",
    "        # Inducive Case: Suppose that the property holds for m=k. Then, we need to prove that it holds for m=k+1.\n",
    "        # The start node is K^k nodes away from the most recent node. But if we use the kth position of the linked\n",
    "        # CIDs, and travelled the kth link (K - 1) times, then the CID to be added to the linked CIDs (at the (k+1)th\n",
    "        # position) is K^k + (K-1) * K^k = K*K^k = K^(k+1), which proves the inductive case.\n",
    "        # Therefore, by the Principle of Mathematical Induction, this theorem holds.\n",
    "        for _ in range(K - 1):\n",
    "            temp_cid = temp_node.cid\n",
    "            temp_node_linked_cids = temp_node.linked_cids\n",
    "            done = j > len(temp_node_linked_cids)\n",
    "            if done:\n",
    "                break\n",
    "            temp_node = ipfs.retrieve(temp_node_linked_cids[-j])\n",
    "        if done:\n",
    "            break\n",
    "        print(temp_node.content)\n",
    "        # Ensure no duplicate links\n",
    "        if temp_node.cid not in linked_cids:\n",
    "            cids.append(temp_node.cid)\n",
    "        j += 1\n",
    "    cids = list(reversed(cids))\n",
    "    linked_cids.extend(cids)\n",
    "    linked_cids.append(latest_node_cid)\n",
    "\n",
    "    print(\"Length of linked_cids: \", len(linked_cids))\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 17\n",
      "Found node: {'CID': 'Qm65f4ea60a75f02e024a3171aaac2bb503a', 'Content': 'Node 17', 'Linked CID(s)': ['Qmba97b515dd042cd5d4c14b9192e4e7cd97', 'Qm4cf86a052fd045c23675bd194af17ab635', 'Qmadd8d2e1a8e5e37d3e3e494406c7be63a7', 'Qmcb754b9cd080484784b2a8c4705fea6dbc', 'Qm54a5099d9a922b1a56bde5e09be246dbef', 'Qmc635416d8199a2ed2ab47c227e1bfa3024'], 'Timestamp': 1737586700.248884}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 112}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.content == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.content == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index -1 (where the latest index is)\n",
    "    node = ipfs.retrieve(linked_cids[-1])\n",
    "    linked_cids = node.linked_cids\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.content == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            print(f\"Found node: {node}\")\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[-1])\n",
    "            linked_cids = node.linked_cids\n",
    "            # Output the found node\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Linking to sequentially uniform N-prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 created with Linked CIDs: []\n",
      "Node 1 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da']\n",
      "Node 2 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm86e1fd7268217acbb34096e13f3ce7ba20']\n",
      "Node 3 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm4f99bcdeea6c1dbde659b4106aaafe45fd']\n",
      "Node 4 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm2bc08578405d9704dac1ec6cf6745256db']\n",
      "Node 5 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm6911d673b184ac20efc254d06b6caf35f7']\n",
      "Node 6 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm84ffbf9ac9c5419dda55c48e8d06f28ca4']\n",
      "Node 7 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm5f4eb738ceb9d803680d3bb91fbd7ba955']\n",
      "Node 8 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm0292e483dc927899733e00cf3e82008581']\n",
      "Node 9 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qma44417fee31c7a31ade00a8ef228a6b198']\n",
      "Node 10 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm86e1fd7268217acbb34096e13f3ce7ba20', 'Qm4f99bcdeea6c1dbde659b4106aaafe45fd', 'Qm2bc08578405d9704dac1ec6cf6745256db', 'Qm6911d673b184ac20efc254d06b6caf35f7', 'Qm84ffbf9ac9c5419dda55c48e8d06f28ca4', 'Qm5f4eb738ceb9d803680d3bb91fbd7ba955', 'Qm0292e483dc927899733e00cf3e82008581', 'Qma44417fee31c7a31ade00a8ef228a6b198', 'Qm1441d7b55ac54b2393c75f8c1923b36a0d']\n",
      "Node 11 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qme561c95e5130bb7ca2d6233cd6a9b3ff5e']\n",
      "Node 12 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm8cfd33e4b59f35e0495fa13ea9d719b644']\n",
      "Node 13 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm4e32b82f5c0e7d70aca7280b78d293b42f']\n",
      "Node 14 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qmf7daa1d5126adf3dbfe83df64ff0feffe5']\n",
      "Node 15 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qmf6f2477babc692c58ad625cb2ba70382af']\n",
      "Node 16 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm6bf6e14cee519fa5d5ce928e8c5c7e29cc']\n",
      "Node 17 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qmd93791ef6f62d0b3251942344715e033a6']\n",
      "Node 18 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm690225b792f3a4e06f288898528317e462']\n",
      "Node 19 created with Linked CIDs: ['Qm9d01eb602dad2fffbd3470cc582db1a8da', 'Qm6dfef256cf87c80146af8790713c11c96c']\n",
      "Node 20 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm8cfd33e4b59f35e0495fa13ea9d719b644', 'Qm4e32b82f5c0e7d70aca7280b78d293b42f', 'Qmf7daa1d5126adf3dbfe83df64ff0feffe5', 'Qmf6f2477babc692c58ad625cb2ba70382af', 'Qm6bf6e14cee519fa5d5ce928e8c5c7e29cc', 'Qmd93791ef6f62d0b3251942344715e033a6', 'Qm690225b792f3a4e06f288898528317e462', 'Qm6dfef256cf87c80146af8790713c11c96c', 'Qmb9c8c2ec8183011524fe89cac0b6790d57']\n",
      "Node 21 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm457d2ad9d003ef51fb6f83b1f6e99fa7df']\n",
      "Node 22 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qmf8d9b874e7d3856951247ec217d0db4258']\n",
      "Node 23 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm7aa93935b520addfc9acbc85d44b0d4c95']\n",
      "Node 24 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm5d247c1955984ca88ce425e57360403694']\n",
      "Node 25 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm5e84abf426abdc45b6c1f754dacc380e45']\n",
      "Node 26 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm9474c5d79c83b259a4fde9e1e6300ee645']\n",
      "Node 27 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm2070f71847655b8cfaa91ae2a3dc01e595']\n",
      "Node 28 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm010548826bf50d35a7678b80818cc445d4']\n",
      "Node 29 created with Linked CIDs: ['Qme561c95e5130bb7ca2d6233cd6a9b3ff5e', 'Qm1755cdd92b995b3eb054c32db3a2063ae9']\n",
      "Node 30 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qmf8d9b874e7d3856951247ec217d0db4258', 'Qm7aa93935b520addfc9acbc85d44b0d4c95', 'Qm5d247c1955984ca88ce425e57360403694', 'Qm5e84abf426abdc45b6c1f754dacc380e45', 'Qm9474c5d79c83b259a4fde9e1e6300ee645', 'Qm2070f71847655b8cfaa91ae2a3dc01e595', 'Qm010548826bf50d35a7678b80818cc445d4', 'Qm1755cdd92b995b3eb054c32db3a2063ae9', 'Qm9fd9ccba4bee39e7870607f50c02709b89']\n",
      "Node 31 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qm7db07ac774b7c21ba0cbeb08a6564c721d']\n",
      "Node 32 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qm2e555aac9f9dd41ec629f5cd2b4664ff79']\n",
      "Node 33 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qma320e5295c398c27bae849af387b3a4d4f']\n",
      "Node 34 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qmf877e846d1ed722ef2cce36778bb35570d']\n",
      "Node 35 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qm27fc4ec0b2e51174918236f2a648202f9e']\n",
      "Node 36 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qm1f28730ce88af935d15065b8b6015f51a5']\n",
      "Node 37 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qmbde668a59afdc684ec78e1f3d2973722d2']\n",
      "Node 38 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qmb8921ee05729bf507a2ef2c6b6dfffb4fb']\n",
      "Node 39 created with Linked CIDs: ['Qm457d2ad9d003ef51fb6f83b1f6e99fa7df', 'Qm6f5a71fae9a53700506cd37fe8994fe2dc']\n",
      "Node 40 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qm2e555aac9f9dd41ec629f5cd2b4664ff79', 'Qma320e5295c398c27bae849af387b3a4d4f', 'Qmf877e846d1ed722ef2cce36778bb35570d', 'Qm27fc4ec0b2e51174918236f2a648202f9e', 'Qm1f28730ce88af935d15065b8b6015f51a5', 'Qmbde668a59afdc684ec78e1f3d2973722d2', 'Qmb8921ee05729bf507a2ef2c6b6dfffb4fb', 'Qm6f5a71fae9a53700506cd37fe8994fe2dc', 'Qmce1b4aea6d20117859b13e1373d68d558b']\n",
      "Node 41 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qm37c2ff402545a4b98b35dd440e49b61830']\n",
      "Node 42 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qmbf23a951a8393b18355512442e296dd093']\n",
      "Node 43 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qmab09451bf04b8098edd29ea8377796334e']\n",
      "Node 44 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qmd02bf431c132ae8317c3aff2efe173d0f5']\n",
      "Node 45 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qm6541b33569e348bdfa03ebad2062444b9d']\n",
      "Node 46 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qm3a34ec7f7793865c0b313ec01e2aea7661']\n",
      "Node 47 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qm48b83fda02bd483855f032920dc569375f']\n",
      "Node 48 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qmdc9ead1b94354b8535d303c084fc967cf8']\n",
      "Node 49 created with Linked CIDs: ['Qm7db07ac774b7c21ba0cbeb08a6564c721d', 'Qmc23908f2f71ee8af293d596a7370a80050']\n",
      "Node 50 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qmbf23a951a8393b18355512442e296dd093', 'Qmab09451bf04b8098edd29ea8377796334e', 'Qmd02bf431c132ae8317c3aff2efe173d0f5', 'Qm6541b33569e348bdfa03ebad2062444b9d', 'Qm3a34ec7f7793865c0b313ec01e2aea7661', 'Qm48b83fda02bd483855f032920dc569375f', 'Qmdc9ead1b94354b8535d303c084fc967cf8', 'Qmc23908f2f71ee8af293d596a7370a80050', 'Qme32e766935285e9525452f70315e5a2853']\n",
      "Node 51 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm99a763f02944e32e2eac076257c3f8bd6e']\n",
      "Node 52 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm934c61ef33b6abb37cfd5f0550af183d98']\n",
      "Node 53 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qmea960c307afc0da15fd9504343b66d0eec']\n",
      "Node 54 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qmf1328cf14b6d88536018f6d38135e16a57']\n",
      "Node 55 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm8710ea60ecb36b4c9b0416b63427b28e07']\n",
      "Node 56 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qmf154031d0a7445a3c974ec7f8221121b02']\n",
      "Node 57 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm7ba4519cfdf069073f5a8b9a5f7b3fac8c']\n",
      "Node 58 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm06cd417667ec8387dafd255ae1047864e0']\n",
      "Node 59 created with Linked CIDs: ['Qm37c2ff402545a4b98b35dd440e49b61830', 'Qm7a8974388d1bf0eb49ddb877de28463432']\n",
      "Node 60 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm934c61ef33b6abb37cfd5f0550af183d98', 'Qmea960c307afc0da15fd9504343b66d0eec', 'Qmf1328cf14b6d88536018f6d38135e16a57', 'Qm8710ea60ecb36b4c9b0416b63427b28e07', 'Qmf154031d0a7445a3c974ec7f8221121b02', 'Qm7ba4519cfdf069073f5a8b9a5f7b3fac8c', 'Qm06cd417667ec8387dafd255ae1047864e0', 'Qm7a8974388d1bf0eb49ddb877de28463432', 'Qm5181390d9cab8799163af38ebb25c8eb22']\n",
      "Node 61 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm26c57862a911a6b91a2c92cc7464c367b8']\n",
      "Node 62 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm8fa7e5d5d59295683be75cd19d9fbe74ca']\n",
      "Node 63 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qmaf51f2aff171e51bc5813571b8a38d083c']\n",
      "Node 64 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm393065c914541eb88273937b69a614823e']\n",
      "Node 65 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm41b975e52c5d45711bd379628f6238bdc3']\n",
      "Node 66 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm3f137260e59ff594e2ceb6f1b2472463bf']\n",
      "Node 67 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qmb09f954a1c519ae4d49274d87a5b46b170']\n",
      "Node 68 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm53790af1594e71f5712be1faf0c0aa44ba']\n",
      "Node 69 created with Linked CIDs: ['Qm99a763f02944e32e2eac076257c3f8bd6e', 'Qm357d8197887da2ee6fa11b0d3c82b66241']\n",
      "Node 70 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qm8fa7e5d5d59295683be75cd19d9fbe74ca', 'Qmaf51f2aff171e51bc5813571b8a38d083c', 'Qm393065c914541eb88273937b69a614823e', 'Qm41b975e52c5d45711bd379628f6238bdc3', 'Qm3f137260e59ff594e2ceb6f1b2472463bf', 'Qmb09f954a1c519ae4d49274d87a5b46b170', 'Qm53790af1594e71f5712be1faf0c0aa44ba', 'Qm357d8197887da2ee6fa11b0d3c82b66241', 'Qm4c78725b3076b02ea45d0068252dc7fc1f']\n",
      "Node 71 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qmebbe0bbca5343ce8cf83e37651dbee1e61']\n",
      "Node 72 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qm296bbf174ffae23200cdccd24136e52678']\n",
      "Node 73 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qm9afb95da2249eb5259e6cd4e36eedaddb4']\n",
      "Node 74 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qma135faf2d060faabcab8889b516850b2ed']\n",
      "Node 75 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qmdc02c015892b818711b41ecc6f86368746']\n",
      "Node 76 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qm1db7e322f4eb9855785556dad083d114e0']\n",
      "Node 77 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qmf1971c9729ca820b0211e8163f50b5829c']\n",
      "Node 78 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qm3d4c2e7f0aa2e2e31a2b9100aa59cea4e7']\n",
      "Node 79 created with Linked CIDs: ['Qm26c57862a911a6b91a2c92cc7464c367b8', 'Qmc9230978512f252aa263e996d856dadf1e']\n",
      "Node 80 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm296bbf174ffae23200cdccd24136e52678', 'Qm9afb95da2249eb5259e6cd4e36eedaddb4', 'Qma135faf2d060faabcab8889b516850b2ed', 'Qmdc02c015892b818711b41ecc6f86368746', 'Qm1db7e322f4eb9855785556dad083d114e0', 'Qmf1971c9729ca820b0211e8163f50b5829c', 'Qm3d4c2e7f0aa2e2e31a2b9100aa59cea4e7', 'Qmc9230978512f252aa263e996d856dadf1e', 'Qm451bbbb69034f02701f4d17ffb2830beaa']\n",
      "Node 81 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm924cb2957ff01d52b18ac8ce79a135be07']\n",
      "Node 82 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qmf6dd9e45230fa363e40ae18a3c30d8b706']\n",
      "Node 83 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm7cd0ee3e4c4379e67ab62e1572495ddd93']\n",
      "Node 84 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm1a7eb23978555371ddb7759895216e46d9']\n",
      "Node 85 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm2369323b6f468c279d37786d05acd8c441']\n",
      "Node 86 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qmc825b25c58af1ea2f7e810bf13a9a493e7']\n",
      "Node 87 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qme50c4a44bb262c3e3d1f2a2824f02a891c']\n",
      "Node 88 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qm2693c0a0debfe98deb301f42e3502f29af']\n",
      "Node 89 created with Linked CIDs: ['Qmebbe0bbca5343ce8cf83e37651dbee1e61', 'Qmbd626e95252d315f3241af17b852a99574']\n",
      "Node 90 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qmf6dd9e45230fa363e40ae18a3c30d8b706', 'Qm7cd0ee3e4c4379e67ab62e1572495ddd93', 'Qm1a7eb23978555371ddb7759895216e46d9', 'Qm2369323b6f468c279d37786d05acd8c441', 'Qmc825b25c58af1ea2f7e810bf13a9a493e7', 'Qme50c4a44bb262c3e3d1f2a2824f02a891c', 'Qm2693c0a0debfe98deb301f42e3502f29af', 'Qmbd626e95252d315f3241af17b852a99574', 'Qm23727e41f1d2a003879a0a7a6917977570']\n",
      "Node 91 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm7603e992e72fb822e4028c2a33a5668f68']\n",
      "Node 92 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm9e1b990ec7172c86b767e5c358c4725c19']\n",
      "Node 93 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm568cb28203aa1abdbb49623e36f873d682']\n",
      "Node 94 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm35eb2ae58f3bd7b1bb7a5f370b431cbec5']\n",
      "Node 95 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm7b91594b56cc84a663d7919a979563e4dc']\n",
      "Node 96 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm72ec7c4195603dfd6aa0a13331cfd556a1']\n",
      "Node 97 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm4413bb31058083b91998452cbc85c9e703']\n",
      "Node 98 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm813e68cd21bb6144d7f8567f06323d9985']\n",
      "Node 99 created with Linked CIDs: ['Qm924cb2957ff01d52b18ac8ce79a135be07', 'Qm779b23a08ae9c0d8b54f0592d9a20afa03']\n",
      "Number of operations IPNS performed:\n",
      "{'get': 101, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 100}\n"
     ]
    }
   ],
   "source": [
    "ipfs.reset_data()\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "N = 10\n",
    "i = 0\n",
    "num_links = max(1, math.floor(NODE_NUM / N))\n",
    "temp_cids = []\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "temp_cids.append(cid)\n",
    "\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "\n",
    "\n",
    "print(f\"Node {0} created with Linked CIDs: {linked_cids}\")\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)\n",
    "temp_cids.append(cid)\n",
    "\n",
    "print(f\"Node {1} created with Linked CIDs: {linked_cids}\")\n",
    "\n",
    "# Automate adding the rest of the nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node\"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.linked_cids\n",
    "    linked_cids = []\n",
    "\n",
    "    # Link to previous node \n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "\n",
    "    if i % num_links == 0:\n",
    "        linked_cids = temp_cids[:]\n",
    "        temp_cids = []\n",
    "\n",
    "    # Create the new node\n",
    "    new_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                     content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, new_node)\n",
    "    ipns.update(URL, cid)\n",
    "    temp_cids.append(cid)\n",
    "\n",
    "    print(f\"Node {i} created with Linked CIDs: {linked_cids}\")\n",
    "\n",
    "# Final output\n",
    "get_op_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node49\n",
      "Can't find node with content: Node49\n",
      "Available contents: []\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 1}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node{node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Retrieve the starting node\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.linked_cids\n",
    "\n",
    "# Traverse the graph using a set to avoid revisiting nodes\n",
    "visited_cids = set()\n",
    "found = False\n",
    "\n",
    "while linked_cids and not found:\n",
    "    next_cids = []\n",
    "    for cid in linked_cids:\n",
    "        if cid in visited_cids:\n",
    "            continue  # Skip already visited nodes\n",
    "        visited_cids.add(cid)\n",
    "        node = ipfs.retrieve(cid)\n",
    "        print(f\"Visiting CID: {cid}, Content: {node.content}\")  # Debug log\n",
    "        if node.content == target_content:\n",
    "            found = True\n",
    "            break\n",
    "        # Add new links to the next search queue\n",
    "        next_cids.extend(node.linked_cids)\n",
    "    linked_cids = next_cids\n",
    "\n",
    "if found:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    print(f\"Can't find node with content: {target_content}\")\n",
    "    all_contents = [ipfs.retrieve(cid).content for cid in visited_cids]\n",
    "    print(f\"Available contents: {all_contents}\")\n",
    "\n",
    "# Output the operation counts\n",
    "get_op_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Other strategies to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
