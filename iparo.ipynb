{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating IPFS and IPNS Systems\n",
    "\n",
    "This notebook provides a Python-based simulation of IPFS (InterPlanetary File System) and IPNS (InterPlanetary Naming System) to test various linking strategies for storing and retrieving IPAROs.\n",
    "\n",
    "The notebook uses three classes to simulate these systems:\n",
    "- **IPARO**: Represents the storage object on IPFS.\n",
    "- **IPNS**: Keeps track of the latest capture for different websites.\n",
    "- **IPFS**: Simulates the hashing, storage, and retrieval of IPARO objects.\n",
    "\n",
    "The goal of the simulation is to test various linking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import hashlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPARO Object\n",
    "\n",
    "**Properties:**\n",
    "- `CID`: The CID (Content Identifier) generated by IPFS.\n",
    "- `Data`: The data of the capture.\n",
    "- `Linked Node CID(s)`: The CID(s) of the nodes linked to it.\n",
    "\n",
    "**Functions:**\n",
    "- `get_cid`: Returns the CID of the IPARO.\n",
    "- `get_linked_cids`: Returns the CID(s) of the linked node(s).\n",
    "- `get_content`: Returns the content of the IPARO.\n",
    "- `__str__`: Returns a string representation of the IPARO object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPARO:\n",
    "    def __init__(self, cid: str, linked_cids: list, content: str, timestamp: str):\n",
    "        \"\"\"\n",
    "        Initialize an IPARO object with its CID, linked CID(s), and content.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the IPARO.\n",
    "            linked_cids (list): List of CIDs of linked nodes.\n",
    "            content (str): The content of the IPARO.\n",
    "        \"\"\"\n",
    "        self.__cid = cid\n",
    "        self.__linked_cids = linked_cids\n",
    "        self.__content = content\n",
    "        self.__timestamp = timestamp\n",
    "\n",
    "    def get_cid(self) -> str:\n",
    "        '''\n",
    "        Returns the CID of the IPARO.\n",
    "\n",
    "        Returns:\n",
    "            str: The CID of the IPARO.\n",
    "        '''\n",
    "        return self.__cid\n",
    "\n",
    "    def get_linked_cids(self) -> list:\n",
    "        '''\n",
    "        Returns the CID(s) of linked nodes.\n",
    "\n",
    "        Returns:\n",
    "            list: List of linked node CIDs.\n",
    "        '''\n",
    "        return self.__linked_cids\n",
    "\n",
    "    def get_content(self) -> str:\n",
    "        '''\n",
    "        Returns the content of the IPARO.\n",
    "\n",
    "        Returns:\n",
    "            str: The content stored in the IPARO.\n",
    "        '''\n",
    "        return self.__content\n",
    "\n",
    "    def get_timestamp(self) -> str:\n",
    "        '''\n",
    "        Returns the timestamp of the IPARO\n",
    "\n",
    "        Returns:\n",
    "            str: The timestamp in seconds since the epoch\n",
    "        '''\n",
    "        return self.__timestamp\n",
    "\n",
    "    def __str__(self):\n",
    "        '''\n",
    "        Returns a string representation of the IPARO object.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the CID, linked CID(s), and content of the IPARO.\n",
    "        '''\n",
    "        iparo = {\n",
    "            \"CID\": self.__cid,\n",
    "            \"Content\": self.__content,\n",
    "            \"Linked CID(s)\": self.__linked_cids,\n",
    "            \"Timestamp\": self.__timestamp,\n",
    "        }\n",
    "        return str(iparo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPNS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPNS class stores and maps the latest CID of a website.\n",
    "- Tracks the number of operations (get and update) performed.\n",
    "\n",
    "**Functions:**\n",
    "- `update`: Updates the latest CID of a website.\n",
    "- `get_cid`: Retrieves the CID of the latest capture for a website.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPNS:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the IPNS object with an empty hashmap for storing CIDs \n",
    "        and counters for tracking operations.\n",
    "        \"\"\"\n",
    "        self.data = {}\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0\n",
    "\n",
    "    def update(self, url, cid):\n",
    "        '''\n",
    "        Updates the latest CID for a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "            cid (str): The CID of the latest capture.\n",
    "        '''\n",
    "        self.update_count += 1\n",
    "        self.data[url] = cid\n",
    "\n",
    "    def get_cid(self, url) -> str:\n",
    "        '''\n",
    "        Retrieves the latest CID for a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "\n",
    "        Returns:\n",
    "            str: The CID of the latest capture for the given URL.\n",
    "        '''\n",
    "        self.get_count += 1\n",
    "        return self.data[url]\n",
    "\n",
    "    def get_counts(self) -> dict:\n",
    "        '''\n",
    "        Returns the number of update and get operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with the counts of update and get operations.\n",
    "        '''\n",
    "        counts = {\"get\": self.get_count, \"update\": self.update_count}\n",
    "        return counts\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operation counters.\n",
    "        \"\"\"\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPFS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPFS class stores the nodes and simulates the hashing, storage, and retrieval operations.\n",
    "- Tracks the number of operations (hash, store, retrieve).\n",
    "\n",
    "**Functions:**\n",
    "- `hash`: Hashes the content of a node to generate its CID.\n",
    "- `store`: Stores a node with its CID.\n",
    "- `retrieve`: Retrieves a node using its CID.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPFS:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize the IPFS object with an empty hashmap for storing nodes\n",
    "        and counters for tracking operations.\n",
    "        '''\n",
    "        self.data = {}\n",
    "        self.hash_count = 0\n",
    "        self.store_count = 0\n",
    "        self.retrieve_count = 0\n",
    "\n",
    "    def hash(self, content: str) -> str:\n",
    "        '''\n",
    "        Hashes the content to generate a CID.\n",
    "\n",
    "        Args:\n",
    "            content (str): The content of the node.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated CID.\n",
    "        '''\n",
    "        sha256_hash = hashlib.sha256(content.encode()).hexdigest()\n",
    "        self.hash_count += 1\n",
    "        return 'Qm' + sha256_hash[:34]\n",
    "\n",
    "    def store(self, cid: str, node: IPARO):\n",
    "        '''\n",
    "        Stores a node with its CID.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the node.\n",
    "            node (IPARO): The IPARO object to store.\n",
    "        '''\n",
    "        self.store_count += 1\n",
    "        self.data[cid] = node\n",
    "\n",
    "    def retrieve(self, cid) -> IPARO:\n",
    "        '''\n",
    "        Retrieves a node using its CID.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the node to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            IPARO: The retrieved IPARO object.\n",
    "        '''\n",
    "        self.retrieve_count += 1\n",
    "        return self.data[cid]\n",
    "\n",
    "    def get_counts(self) -> dict:\n",
    "        '''\n",
    "        Returns the number of hash, store, and retrieve operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with counts of hash, store, and retrieve operations.\n",
    "        '''\n",
    "        counts = {\"hash\": self.hash_count, \"store\": self.store_count,\n",
    "                  \"retrieve\": self.retrieve_count}\n",
    "        return counts\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operation counters.\n",
    "        \"\"\"\n",
    "        self.hash_count = 0\n",
    "        self.store_count = 0\n",
    "        self.retrieve_count = 0\n",
    "\n",
    "    def reset_data(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def get_data(self) -> dict:\n",
    "        \"\"\"Returns the data stored by IPFS (for debugging).\"\"\"\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Operation Tracking\n",
    "\n",
    "Here, we initialize the IPFS and IPNS objects and define a helper function `get_op_counts()` to display the number of operations performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the simulated IPFS and IPNS\n",
    "ipfs = IPFS()\n",
    "ipns = IPNS()\n",
    "\n",
    "\n",
    "def get_op_counts():\n",
    "    '''\n",
    "    Displays the number of operations performed by IPNS and IPFS.\n",
    "    '''\n",
    "    print(\"Number of operations IPNS performed:\")\n",
    "    print(ipns.get_counts())\n",
    "    print(\"Number of operations IPFS performed:\")\n",
    "    print(ipfs.get_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Linking Strategies\n",
    "\n",
    "### 1. Linking to Only the Previous Node\n",
    "\n",
    "In this test, each node will link only to the previous node in the chain. This strategy will be used to simulate a simple sequential storage system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 99, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 0}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "\n",
    "# Automate the creation of additional nodes\n",
    "for i in range(1, NODE_NUM):\n",
    "    content = f\"Node {i}\"\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    linked_cids = [ipns.get_cid(URL)]  # Link to the previous node\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 94\n",
      "Found node: {'CID': 'Qm28de24571502f3dd124f62479d22c09928', 'Content': 'Node 94', 'Linked CID(s)': ['Qm132611ae6e39d2ac33380d2eaa7e3142fc'], 'Timestamp': 1732065991.908295}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 6}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "while node.get_content() != target_content:\n",
    "    node = ipfs.retrieve(node.get_linked_cids()[0])\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linking to all previous nodes\n",
    "\n",
    "In this test, each node will link to all the previous nodes in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, there are 2 ways of creating a new node for this linking strategy, since this is a simulation, no data corruption can happen but that might not be true in practice. When retrieving the latest node which should contain the CIDs of all the previous node, two scenarios can happen:\n",
    "1. The data is intact and the CIDs in the list is \"correct\" (which we really can't know for sure) and we can just add it to the new node we're creating\n",
    "2. The data is corrupt and one or more of the CIDs is wrong or unfinished, in which case we have to recheck every CID to rebuild a new list of linked CIDs (not to mention fixing all the corrupted nodes)\n",
    "\n",
    "So, for the purpose of this simulation, we will perform a check for every CID in the linked CID list of an IPARO to simulate the worst case scenario every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 4955}\n"
     ]
    }
   ],
   "source": [
    "# To automate adding the rest of the nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    linked_cids = []\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = latest_node_linked_cids\n",
    "    for link_cid in latest_node_linked_cids:\n",
    "        ipfs.retrieve(link_cid)\n",
    "        # Checking and repairing nodes goes here\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worst case scenario, where we have to retrieve and verify every CIDs in the linked CIDs of an IPARO, the retrieve count goes to almost 5000 (if we're storing 100 nodes)\\\n",
    "Of course this trade off makes it really easy to navigate to all the nodes just from the latest nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 42\n",
      "Found node: {'CID': 'Qm9bbc52fbd4529a6bb0aa22a371c19a05a1', 'Content': 'Node 42', 'Linked CID(s)': ['Qm3bfbe4bddcd39c398727c9fe56691a97c9', 'Qm20251bc29c597374d12e4bf1a6ccd936bf', 'Qm362ee97b028ce03436e084cd2f4f94f7f4', 'Qm2a9bd593006fbd0b84150f7951ce4dc324', 'Qmacbb9d9e69ef5b63649f7c3ec8b0d4d7ad', 'Qm04de198dcd287a1c63152f9d09bfecd07a', 'Qm97eba64d75445f64b6c52af91b842e0c89', 'Qm1c0581c235d7655e7336f44ddfc1e90755', 'Qm7b49e158aba728b47665c7493b6ba3b0dd', 'Qm835348af2f32a651c17990daceac738aa6', 'Qm1151c18844ee168417364ff5b5e3f58621', 'Qmfb239c7a2e9b290932b7bb968a79e23a19', 'Qm7198e61aac8e35e22658e1aca990db39bf', 'Qm4e52e13eaec07a246f45e5b129f81c144a', 'Qm7f179472f71dee2dc3132496a4b9befb3e', 'Qm3e83b2057d411686b0f1ab8426242e5faf', 'Qmf6db185d7f4682a233653ce25a74a7aea7', 'Qm6a6915acd0ebb1bd4f71550eafe224d802', 'Qm093be6239ce965ba709e8a13c6d000b10c', 'Qm6501c4a4a13f6bba1f3b5ae39d5f85ca5f', 'Qm074b479ac4ee59dbb145d2c11646c4338b', 'Qm3e54a0bf09e618e5cf98e7c3ff53ff5f44', 'Qmc60672737628704fab221bb6cc0792d4ac', 'Qm1709d31c8a958e624b0076befbb9b54925', 'Qm9c542e7f90b41b7c90c680c1d0e3a8a337', 'Qm9866aa11bf2484a2d770ae52ae00dfd76f', 'Qmfe9b55a2ab6190087c976b9ccacbceebc9', 'Qme2e0a0f4d5c3ad16705f7c8c86e22bb550', 'Qmf7ba32e15d236698efb186aba3b66cb857', 'Qmd616b5b5bb87ecf1fed912e9fee35ae819', 'Qm469e683e7023fc86f87ac0111e7d3163b8', 'Qm5e40b4121e2f307b8e1f10f665c9ea14a3', 'Qmfe400841ec5a2954bc383c3fcf63c26aa0', 'Qm831b7a9f4f4890c5f78e7a7ee0c33d3f6e', 'Qm5c86afdbcfb6c816917ea448a9a2ccb50f', 'Qmb4797cc755d0e728aa87f3db5db718bf84', 'Qm52fe74d8207fd567e6db9ab3b1e382fe45', 'Qm64e4353a4bea822f56ac5c09b9ef56e0c2', 'Qm82407f35419eb76ea42e7fb935cfc81eca', 'Qmd1c226f792eec728e0d1311571bc056a97', 'Qm3b6f8d461cd6fb8296963eb7fc6ed82152', 'Qm77d284e5f576322138df0c2b70180900b7', 'Qm9bbc52fbd4529a6bb0aa22a371c19a05a1', 'Qm746ea66b3bd8a4365d9ac42b8c6b351b95', 'Qm0ba43e4c351dd814facfa06841ff1bc2bf', 'Qm3b6b611f82898b34904a916c570a181c49', 'Qm5d6ac9cf41e6ed5420d97e18386439c0f0', 'Qmec2c6a74b1bf2a06cc884cec2d8684e582', 'Qmd65a27e1da5bb57139fc3063dd9eadd10b', 'Qm2577f19c3ef99bbdf760f62565e1f25467', 'Qm809d4af17b070d18c370ef0301e3b29eeb', 'Qme2ab839e8cf77ec28096a3dc9c019d9641', 'Qm7f6d56e6eba538ee1f2d098007c39e46fa', 'Qmd7492cebda09b15782873d6f88321cd4d8', 'Qm95eb3990ead37c5f0fab68c0321a4a35e4', 'Qm2bffff328a7a0509e339c8e6ec5ebd9195', 'Qm319a481c7975a207457905835416f8c2b0', 'Qm649712b921dc3651f3b0b5ab78b2c5fa62', 'Qmc00beac749f5d78135413f7939c16065e4', 'Qm54a488b2f280a914b769784aff066f5f7a', 'Qmdccebd6bd8ea950c975bdedc79b03ea139', 'Qm1b5242cd2942096e808989666c4695c1a7', 'Qm9a76ec7691e7cebaca0a91c26949eb3988', 'Qm30c87db4a0e7ee79453a181c9cc034e43b', 'Qmbc3d5546a3cae202da01075cece77f69cb', 'Qmfa6fedbdf70e9cb55cc578002483dd4cf0', 'Qm1f8d9e3664219165973276869a915b27f0', 'Qmcece2e7dd34ad6535df9dc2514ebcbd683', 'Qm0ce735c4d481f771e4b8be635c285bb35c', 'Qm4e3e0d65dd2d87797214265eb024ba4c0f', 'Qm5f6d7270d938c9075bc1944f460bba6b16', 'Qm2ec88e9df55c439320027df0da04e36692', 'Qm472724840a9eecf951cbf43fa23e284c11', 'Qmce722c58eaaf42711e0e9e5592edd23e08', 'Qm2afae251c319e8bc37d1eb70a82943a526', 'Qm8e06e250eeac94120ac96a48efe8ea42d8', 'Qm603e72cf77384e9953486663b368ade163', 'Qm9f5167aeeff6a3eb96923f05bbeab61c40', 'Qm52134e3b539250555c26cea358faf70035', 'Qm6d03739381d52424ef9a662fb333a91f96', 'Qme79a1437f40fbe7c1cae0e3ab325fcbadd', 'Qmed0324e1f1bac1f15452dc066be8ac0c4a', 'Qm737d98de482fe56d520e8a59ad7e84f5c5', 'Qmaea35d6feee7289ac3bcf319c099f006c5', 'Qm8e3dbae016ea67bde131921864fa494ff7', 'Qm6d270252a31826b5ca92a1658ea99ae2c8', 'Qm8ccd2f32d87e875246c18262bd97b10584', 'Qm75324ecbc1af840f3059d1409194e849ff', 'Qm00ce270da6dbc987f170d7b2e3e2c33573', 'Qmceec8d172d6b47140bfc1711753c959b7e', 'Qm02e1a45af8512cf0d4d79f0c93f519237d', 'Qm6c4870fd105ca202eaf7c70b28ae1f74a2', 'Qmcf1eb622ecb8bfedf7782fabbf63982e49', 'Qm865266789f9f859b6babd37337fb0b8355', 'Qm46cab8ce31db9af3b6aa2fd26a58f56383', 'Qm24fcfba07160e108de249f641ca0af4d61', 'Qm1fd3b8a9b07c5bbfaa534e85bfb2b95799', 'Qm6a27836b74a483bef68dcb0aea27134a88', 'Qm0d0bb26eb57e139ff94056bf55e214b06f'], 'Timestamp': 1732065991.9517355}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 44}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "for linked_cid in linked_cids:\n",
    "    node = ipfs.retrieve(linked_cid)\n",
    "    if node.get_content() == target_content:\n",
    "        break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linking to previous and first node\n",
    "\n",
    "In this test, each node will link to the previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 142}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    linked_cids = []\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 85\n",
      "Found node: {'CID': 'Qm820ddadec30147ac577de08c9180407ef5', 'Content': 'Node 85', 'Linked CID(s)': ['Qm656bd171d76fe39c63a742e41698897c8d', 'Qmc32f3bd8c4f250befe632727ae84203bf0'], 'Timestamp': 1732065991.994444}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 16}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    while True:\n",
    "        node = ipfs.retrieve(linked_cids[1])\n",
    "        linked_cids = node.get_linked_cids()\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linking to K-previous and first node\n",
    "\n",
    "In this test, each node will link to K previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "K = 5\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 114}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = []\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    if len(latest_node_linked_cids) == K+1:\n",
    "        linked_cids.extend(latest_node_linked_cids[2:])\n",
    "        linked_cids.append(latest_node_cid)\n",
    "    else:\n",
    "        linked_cids.extend(latest_node_linked_cids[1:])\n",
    "        linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 48\n",
      "Found node: {'CID': 'Qmcb7a8450120e832d7c76137f4021134176', 'Content': 'Node 48', 'Linked CID(s)': ['Qm5352c38f80d9d8d7caefb9ff9c29dbf324', 'Qma11ce9161ca9a3e719637216ab0b6e716b', 'Qmdcdbdf686e632621bb149fe06f309de850', 'Qmcb3eb99e7f0a27971e7fcc07f8d18fa8d6', 'Qm7790335b990a338bf4be384b6571e3a16f', 'Qm810d790dc6bea7f0f66835499f070218fc'], 'Timestamp': 1732065992.0272117}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 68}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index 1\n",
    "    node = ipfs.retrieve(linked_cids[1])\n",
    "    linked_cids = node.get_linked_cids()\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.get_content() == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[1])\n",
    "            linked_cids = node.get_linked_cids()\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other strategies to be tested"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
