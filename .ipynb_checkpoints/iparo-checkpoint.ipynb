{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating IPFS and IPNS Systems\n",
    "\n",
    "This notebook provides a Python-based simulation of IPFS (InterPlanetary File System) and IPNS (InterPlanetary Naming System) to test various linking strategies for storing and retrieving IPAROs.\n",
    "\n",
    "The notebook uses three classes to simulate these systems:\n",
    "- **IPARO**: Represents the storage object on IPFS.\n",
    "- **IPNS**: Keeps track of the latest capture for different websites.\n",
    "- **IPFS**: Simulates the hashing, storage, and retrieval of IPARO objects.\n",
    "\n",
    "The goal of the simulation is to test various linking strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import hashlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPARO Object\n",
    "\n",
    "**Properties:**\n",
    "- `CID`: The CID (Content Identifier) generated by IPFS.\n",
    "- `Data`: The data of the capture.\n",
    "- `Linked Node CID(s)`: The CID(s) of the nodes linked to it.\n",
    "\n",
    "**Functions:**\n",
    "- `get_cid`: Returns the CID of the IPARO.\n",
    "- `get_linked_cids`: Returns the CID(s) of the linked node(s).\n",
    "- `get_content`: Returns the content of the IPARO.\n",
    "- `__str__`: Returns a string representation of the IPARO object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPARO:\n",
    "    def __init__(self, cid: str, linked_cids: list, content: str, timestamp: str):\n",
    "        \"\"\"\n",
    "        Initialize an IPARO object with its CID, linked CID(s), and content.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the IPARO.\n",
    "            linked_cids (list): List of CIDs of linked nodes.\n",
    "            content (str): The content of the IPARO.\n",
    "        \"\"\"\n",
    "        self.__cid = cid\n",
    "        self.__linked_cids = linked_cids\n",
    "        self.__content = content\n",
    "        self.__timestamp = timestamp\n",
    "\n",
    "    def get_cid(self) -> str:\n",
    "        '''\n",
    "        Returns the CID of the IPARO.\n",
    "\n",
    "        Returns:\n",
    "            str: The CID of the IPARO.\n",
    "        '''\n",
    "        return self.__cid\n",
    "\n",
    "    def get_linked_cids(self) -> list:\n",
    "        '''\n",
    "        Returns the CID(s) of linked nodes.\n",
    "\n",
    "        Returns:\n",
    "            list: List of linked node CIDs.\n",
    "        '''\n",
    "        return self.__linked_cids\n",
    "\n",
    "    def get_content(self) -> str:\n",
    "        '''\n",
    "        Returns the content of the IPARO.\n",
    "\n",
    "        Returns:\n",
    "            str: The content stored in the IPARO.\n",
    "        '''\n",
    "        return self.__content\n",
    "\n",
    "    def get_timestamp(self) -> str:\n",
    "        '''\n",
    "        Returns the timestamp of the IPARO\n",
    "\n",
    "        Returns:\n",
    "            str: The timestamp in seconds since the epoch\n",
    "        '''\n",
    "        return self.__timestamp\n",
    "\n",
    "    def __str__(self):\n",
    "        '''\n",
    "        Returns a string representation of the IPARO object.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the CID, linked CID(s), and content of the IPARO.\n",
    "        '''\n",
    "        iparo = {\n",
    "            \"CID\": self.__cid,\n",
    "            \"Content\": self.__content,\n",
    "            \"Linked CID(s)\": self.__linked_cids,\n",
    "            \"Timestamp\": self.__timestamp,\n",
    "        }\n",
    "        return str(iparo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPNS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPNS class stores and maps the latest CID of a website.\n",
    "- Tracks the number of operations (get and update) performed.\n",
    "\n",
    "**Functions:**\n",
    "- `update`: Updates the latest CID of a website.\n",
    "- `get_cid`: Retrieves the CID of the latest capture for a website.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPNS:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the IPNS object with an empty hashmap for storing CIDs \n",
    "        and counters for tracking operations.\n",
    "        \"\"\"\n",
    "        self.data = {}\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0\n",
    "\n",
    "    def update(self, url, cid):\n",
    "        '''\n",
    "        Updates the latest CID for a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "            cid (str): The CID of the latest capture.\n",
    "        '''\n",
    "        self.update_count += 1\n",
    "        self.data[url] = cid\n",
    "\n",
    "    def get_cid(self, url) -> str:\n",
    "        '''\n",
    "        Retrieves the latest CID for a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the website.\n",
    "\n",
    "        Returns:\n",
    "            str: The CID of the latest capture for the given URL.\n",
    "        '''\n",
    "        self.get_count += 1\n",
    "        return self.data[url]\n",
    "\n",
    "    def get_counts(self) -> dict:\n",
    "        '''\n",
    "        Returns the number of update and get operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with the counts of update and get operations.\n",
    "        '''\n",
    "        counts = {\"get\": self.get_count, \"update\": self.update_count}\n",
    "        return counts\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operation counters.\n",
    "        \"\"\"\n",
    "        self.update_count = 0\n",
    "        self.get_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPFS Object\n",
    "\n",
    "**Description:**\n",
    "- The IPFS class stores the nodes and simulates the hashing, storage, and retrieval operations.\n",
    "- Tracks the number of operations (hash, store, retrieve).\n",
    "\n",
    "**Functions:**\n",
    "- `hash`: Hashes the content of a node to generate its CID.\n",
    "- `store`: Stores a node with its CID.\n",
    "- `retrieve`: Retrieves a node using its CID.\n",
    "- `get_counts`: Returns the number of operations performed.\n",
    "- `reset_counts`: Resets the counters for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPFS:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize the IPFS object with an empty hashmap for storing nodes\n",
    "        and counters for tracking operations.\n",
    "        '''\n",
    "        self.data = {}\n",
    "        self.hash_count = 0\n",
    "        self.store_count = 0\n",
    "        self.retrieve_count = 0\n",
    "\n",
    "    def hash(self, content: str) -> str:\n",
    "        '''\n",
    "        Hashes the content to generate a CID.\n",
    "\n",
    "        Args:\n",
    "            content (str): The content of the node.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated CID.\n",
    "        '''\n",
    "        sha256_hash = hashlib.sha256(content.encode()).hexdigest()\n",
    "        self.hash_count += 1\n",
    "        return 'Qm' + sha256_hash[:34]\n",
    "\n",
    "    def store(self, cid: str, node: IPARO):\n",
    "        '''\n",
    "        Stores a node with its CID.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the node.\n",
    "            node (IPARO): The IPARO object to store.\n",
    "        '''\n",
    "        self.store_count += 1\n",
    "        self.data[cid] = node\n",
    "\n",
    "    def retrieve(self, cid) -> IPARO:\n",
    "        '''\n",
    "        Retrieves a node using its CID.\n",
    "\n",
    "        Args:\n",
    "            cid (str): The CID of the node to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            IPARO: The retrieved IPARO object.\n",
    "        '''\n",
    "        self.retrieve_count += 1\n",
    "        return self.data[cid]\n",
    "\n",
    "    def get_counts(self) -> dict:\n",
    "        '''\n",
    "        Returns the number of hash, store, and retrieve operations performed.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with counts of hash, store, and retrieve operations.\n",
    "        '''\n",
    "        counts = {\"hash\": self.hash_count, \"store\": self.store_count,\n",
    "                  \"retrieve\": self.retrieve_count}\n",
    "        return counts\n",
    "\n",
    "    def reset_counts(self):\n",
    "        \"\"\"\n",
    "        Resets the operation counters.\n",
    "        \"\"\"\n",
    "        self.hash_count = 0\n",
    "        self.store_count = 0\n",
    "        self.retrieve_count = 0\n",
    "\n",
    "    def reset_data(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def get_data(self) -> dict:\n",
    "        \"\"\"Returns the data stored by IPFS (for debugging).\"\"\"\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Operation Tracking\n",
    "\n",
    "Here, we initialize the IPFS and IPNS objects and define a helper function `get_op_counts()` to display the number of operations performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the simulated IPFS and IPNS\n",
    "ipfs = IPFS()\n",
    "ipns = IPNS()\n",
    "\n",
    "\n",
    "def get_op_counts():\n",
    "    '''\n",
    "    Displays the number of operations performed by IPNS and IPFS.\n",
    "    '''\n",
    "    print(\"Number of operations IPNS performed:\")\n",
    "    print(ipns.get_counts())\n",
    "    print(\"Number of operations IPFS performed:\")\n",
    "    print(ipfs.get_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Linking Strategies\n",
    "\n",
    "### 1. Linking to Only the Previous Node\n",
    "\n",
    "In this test, each node will link only to the previous node in the chain. This strategy will be used to simulate a simple sequential storage system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 99, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 0}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "\n",
    "# Automate the creation of additional nodes\n",
    "for i in range(1, NODE_NUM):\n",
    "    content = f\"Node {i}\"\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    linked_cids = [ipns.get_cid(URL)]  # Link to the previous node\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 86\n",
      "Found node: {'CID': 'Qm22c64d2739efefae7a8632e8c752d4f7fa', 'Content': 'Node 86', 'Linked CID(s)': ['Qm8e1780134b0ad64739805235549ef295f4'], 'Timestamp': 1737219680.2209897}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 14}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "while node.get_content() != target_content:\n",
    "    node = ipfs.retrieve(node.get_linked_cids()[0])\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linking to all previous nodes\n",
    "\n",
    "In this test, each node will link to all the previous nodes in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, there are 2 ways of creating a new node for this linking strategy, since this is a simulation, no data corruption can happen but that might not be true in practice. When retrieving the latest node which should contain the CIDs of all the previous node, two scenarios can happen:\n",
    "1. The data is intact and the CIDs in the list is \"correct\" (which we really can't know for sure) and we can just add it to the new node we're creating\n",
    "2. The data is corrupt and one or more of the CIDs is wrong or unfinished, in which case we have to recheck every CID to rebuild a new list of linked CIDs (not to mention fixing all the corrupted nodes)\n",
    "\n",
    "So, for the purpose of this simulation, we will perform a check for every CID in the linked CID list of an IPARO to simulate the worst case scenario every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 4963}\n"
     ]
    }
   ],
   "source": [
    "# To automate adding the rest of the nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    linked_cids = []\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = latest_node_linked_cids\n",
    "    for link_cid in latest_node_linked_cids:\n",
    "        ipfs.retrieve(link_cid)\n",
    "        # Checking and repairing nodes goes here\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worst case scenario, where we have to retrieve and verify every CIDs in the linked CIDs of an IPARO, the retrieve count goes to almost 5000 (if we're storing 100 nodes)\\\n",
    "Of course this trade off makes it really easy to navigate to all the nodes just from the latest nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving nodes\n",
    "\n",
    "The following section tests retrieval of nodes by simulating a random node search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 11\n",
      "Found node: {'CID': 'Qm1b1e163a87a876ac72c1363d3642f163e4', 'Content': 'Node 11', 'Linked CID(s)': ['Qm74075d1df32399978be1482d2da515ef93', 'Qme1dac373c7aa880e9a5c913ba3331f7764', 'Qm8a07fb0d9976860d66b6b6869be9a54a3b', 'Qm2b164f0d584b104b4e111e9b7f3a53988f', 'Qm24f765e759304b8ac1988883d20873a04b', 'Qmb06a3905344b4f67555363e04146c1f9d0', 'Qmba753741ba99805d94dbb78a0846b315b3', 'Qmacdbe90430821e7f42b46f623e5e245325', 'Qmb564301b57c04e5ab57d90236bb79f2858', 'Qmd51502456bd0000bcd7b7c2827c352624a', 'Qm0912585122fe715c8d7881b54d9b6d0209', 'Qm1b1e163a87a876ac72c1363d3642f163e4', 'Qmfefcdc54347b5f084c0d2d3a15d0c22433', 'Qme83ddae631b6478d09aee57f95fb6d143d', 'Qm397a79520a7249c41d437e3baa24a5aafa', 'Qmbe05ee30b6d03a897fe384f2d15731c65f', 'Qm239310cab7418d506c1c7c571625d9a731', 'Qmc8d80ceaae0ecb26bce5ad769cdc74a990', 'Qmce3be00c1f7eb6f2e86f2cdc7808f4eccc', 'Qmcebef27b348dc52aaeddbb860186679715', 'Qma4a576d9a17d81be2c6f2b8eb02f5c70fc', 'Qm357f88fc7fedc87956f4ee383d52a304ba', 'Qmf6050dcc06a40c3261980325c63542331f', 'Qm07e8d2707b8bbf0a8b2079a708c1331827', 'Qmd9a70a83d4f9a8c85097d137cd86231786', 'Qm17087ddf862b7b60a2e2e87d408e3aeded', 'Qmb2db2e5ac7b6b2c8a0394b49d345f48c3a', 'Qmd28f4b18312619a8be7d6ef13c9e1b393f', 'Qm0843e6d3cac132fb935ff636e5811035a9', 'Qm446ccc711a6ddaae004bf6bca5fad3ad49', 'Qm71bc4b6cc410e590526f0c32e7be050369', 'Qm96f4bf1171de571b0cc941e62ed84d1cfe', 'Qm8b0eb2b4a1b3dcc783949ddd06761fc3a6', 'Qm8f63ef15a4c073fd4504a87de79670148f', 'Qme2d06d6be66be63d69e405481efda03d87', 'Qmd21dc35902f40eae7c4dda152e53ef7285', 'Qmbb0d9006ca170d3c7206e1655f72c5f330', 'Qmefd10886624bb121f4ede67f4e6858db42', 'Qm7af989125c6973e14a9abfec6669df0b2b', 'Qm65731cbf00f816c0cf7c1848803ec9ce1b', 'Qm0e08a5e2899059ef1e843fc3d19c1c5818', 'Qm7e8fc93ce413af9d162e14da5edcbcc416', 'Qme5116dc758db98aafb632bac688b1cb7c5', 'Qmc32b6fd61d7a90c36691ccab898f12af7b', 'Qm05a618e5d178f4d6e303eb9999241e9bce', 'Qme40340bed60a4c10fcf70120d7c51392de', 'Qmdd67a12482318bb96ace0b1c6b820d96c0', 'Qmd72994115f61d4956b2f8184d5dfccde3f', 'Qmba08dadbaa7d56a831c2cf9f36d133d888', 'Qma642fdb5aab72baf65f556a02aaa4dfc5a', 'Qm07479fa388f4dfc047b0fc84a686640347', 'Qmedcb175f189054811afe37ada94fa6df4d', 'Qme58ac84c83a87e22adc60b083223bb529c', 'Qm67b175d2970ddd3ab12f4aaf77230d5b35', 'Qm7487f2de418cc6c033a19eba932df98003', 'Qm233690c5b5aeecebb3190f18772fdd17a3', 'Qme29249bdaa760fde63fd4c202224cfed50', 'Qm6952139a9e5b6723e6b1a7ef971b5beece', 'Qm401b1579a8ae58071b5eee42cca4c075e7', 'Qmd54604fa7d8b04dbee4f793ad8d5f67edf', 'Qm3aafbd29502f03a28e8aea21afcae9effb', 'Qm80cfc85e3a61e31bb18582de789ea89019', 'Qmdc71db470b99a13965a19953156cc2c0f4', 'Qm9b6c51b6cbc8f75cf6c4099870df471905', 'Qm521e48147a4945693c394e647adace390b', 'Qmdc5692e9f3db6ab3570b58951f1976c344', 'Qm9db2830cfb69c5f3f1c330640fb26aa110', 'Qm12fa5bc2b69083ed2b1ae099bcd3b769cb', 'Qm408ca0417e3a8e0e513bb492d7942477bc', 'Qmde4f01659669682ec39d24788337dcfd73', 'Qme04fc74fc423cf1a6e71a9a345098f9b72', 'Qm52711751c3d3394fb90cb5c75d226a5b11', 'Qmc82d527d7a5f3bceb4352612a5cea18401', 'Qmd77238e3e814fa296431e32cc28bf471db', 'Qmc53573cc154f12eb986c7642b26d7090ee', 'Qme972763793e57401d714bfe09b86dc2e22', 'Qmed07a314575c4b41b19d3c8da525863d23', 'Qm2b269bc412b5bc2df038406d812cf368f1', 'Qmcddf7d886103397c79d34ddd08a82ee435', 'Qm16c359534545700bc9b0125d4fbfaf982c', 'Qm035f38e89c3dfe12b3958968a55f21e814', 'Qma6fb0943e5a0fc0c19f77ac2a118568b1f', 'Qm5c3640f87d5d6ae8433ea24db0d96e1140', 'Qmbaaf9ef34cf3ab93cd0972ea85c90f17ac', 'Qm980c9e7356f97368cad4347346bcc16fd5', 'Qm248fa179b19bf92c9881edda23dc715532', 'Qm549ed1cff7915f904f1b7ff2f894458d6e', 'Qmfd1c025ba8fca49077c78add8fd3f8ca8a', 'Qm802bac2e7bf31a1b10c54d299160b5f055', 'Qmd8871b96b1a83661d65d3d48b9ebccc496', 'Qm5edfa93636807bf9354147f99c9b448dc5', 'Qm9026c35af3d149c2b60855f1eceed531f4', 'Qmc3c7adcb72a07eac9924c2d6faf28b0c98', 'Qme65188ab3b6459d962ccaf76114b72271f', 'Qm87a31841a993ba841d31995447983f8815', 'Qme3aebdcd2e15e94398c85a07adcbe56d4a', 'Qmaa39e0c6e661a9cbd0d86a606c20806f0a', 'Qmefc9d6ea5979a5caf77621139876630b9f', 'Qm1cc57f8edd08f439e2d4f98dd57d0e4bff'], 'Timestamp': 1737219680.2573426}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 13}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Traverse back through the linked nodes to find the target\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "for linked_cid in linked_cids:\n",
    "    node = ipfs.retrieve(linked_cid)\n",
    "    if node.get_content() == target_content:\n",
    "        break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linking to previous and first node\n",
    "\n",
    "In this test, each node will link to the previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 139}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    linked_cids = []\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "# print(ipfs.get_data())\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 90\n",
      "Found node: {'CID': 'Qmc0187f924869a07a418bd8e2b99b5a9d3f', 'Content': 'Node 90', 'Linked CID(s)': ['Qmbe77950e4b572465af416fdb2ba7694dd5', 'Qmf3786d0f2006c25a313de74e4aa14992d4'], 'Timestamp': 1737222945.0940273}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 11}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    while True:\n",
    "        node = ipfs.retrieve(linked_cids[1])\n",
    "        linked_cids = node.get_linked_cids()\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linking to K-previous and first node\n",
    "\n",
    "In this test, each node will link to K previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 100\n",
    "URL = \"example.com\"\n",
    "K = 5\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations IPNS performed:\n",
      "{'get': 100, 'update': 100}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 100, 'store': 100, 'retrieve': 174}\n"
     ]
    }
   ],
   "source": [
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = []\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    if len(latest_node_linked_cids) == K+1:\n",
    "        linked_cids.extend(latest_node_linked_cids[2:])\n",
    "    else:\n",
    "        linked_cids.extend(latest_node_linked_cids[1:])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 58\n",
      "Found node: {'CID': 'Qm9549b5b013a743ac04c8c23d392a173a9e', 'Content': 'Node 58', 'Linked CID(s)': ['Qm2088883a7713e18efe5e994f9b94a3e877', 'Qm6b740d154133c853c583aede5fbddbfe9d', 'Qme96d8950e1c4d6fbf01c96f3dbb440d5e3', 'Qm2f7be594a77e71d7cb7a14cc4c560e6585', 'Qm5575928951d74aaa6783280052d238dda7', 'Qmd84ca238f043cae0222708fd58a285d438'], 'Timestamp': 1737219680.3335264}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 56}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index 1\n",
    "    node = ipfs.retrieve(linked_cids[1])\n",
    "    linked_cids = node.get_linked_cids()\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.get_content() == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[1])\n",
    "            linked_cids = node.get_linked_cids()\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Linking to K-random and first node\n",
    "\n",
    "In this test, each node will link to a random K previous node and the first node in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  11\n",
      "Length of linked_cids:  2\n",
      "{'CID': 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Content': 'Node 2', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa'], 'Timestamp': 1737222966.4240603}\n",
      "K =  8\n",
      "Length of linked_cids:  3\n",
      "{'CID': 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Content': 'Node 3', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6'], 'Timestamp': 1737222966.4245827}\n",
      "K =  8\n",
      "Length of linked_cids:  4\n",
      "{'CID': 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Content': 'Node 4', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c'], 'Timestamp': 1737222966.4245827}\n",
      "K =  11\n",
      "Length of linked_cids:  5\n",
      "{'CID': 'Qmd16583be1e8339044a7e40029c196b1004', 'Content': 'Node 5', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm24fbe9dc21ffbf1176b019dbb512279fde'], 'Timestamp': 1737222966.4245827}\n",
      "K =  10\n",
      "Length of linked_cids:  6\n",
      "{'CID': 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Content': 'Node 6', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmd16583be1e8339044a7e40029c196b1004'], 'Timestamp': 1737222966.4245827}\n",
      "K =  11\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Content': 'Node 7', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmd16583be1e8339044a7e40029c196b1004', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014'], 'Timestamp': 1737222966.4245827}\n",
      "K =  6\n",
      "Length of linked_cids:  6\n",
      "{'CID': 'Qm9557d4f5f10bbe3e63008382ec230bf812', 'Content': 'Node 8', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm7d99d54388e95cbcba31fd904f02d22737'], 'Timestamp': 1737222966.4245827}\n",
      "K =  8\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Content': 'Node 9', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm9557d4f5f10bbe3e63008382ec230bf812'], 'Timestamp': 1737222966.4245827}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qmb45b26ef47ac4c90890a5d777dde81a76a', 'Content': 'Node 10', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b'], 'Timestamp': 1737222966.4245827}\n",
      "K =  9\n",
      "Length of linked_cids:  8\n",
      "{'CID': 'Qma5740c4396f17340f401f06ce65e58675a', 'Content': 'Node 11', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qmb45b26ef47ac4c90890a5d777dde81a76a'], 'Timestamp': 1737222966.4245827}\n",
      "K =  11\n",
      "Length of linked_cids:  9\n",
      "{'CID': 'Qmfa7a61424bcf0f1f8afe1637c928a83bb0', 'Content': 'Node 12', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qmb45b26ef47ac4c90890a5d777dde81a76a', 'Qma5740c4396f17340f401f06ce65e58675a'], 'Timestamp': 1737222966.4245827}\n",
      "K =  10\n",
      "Length of linked_cids:  10\n",
      "{'CID': 'Qm257646aee4ad89efb091b616c783c6c70a', 'Content': 'Node 13', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qmb45b26ef47ac4c90890a5d777dde81a76a', 'Qma5740c4396f17340f401f06ce65e58675a', 'Qmfa7a61424bcf0f1f8afe1637c928a83bb0'], 'Timestamp': 1737222966.4245827}\n",
      "K =  9\n",
      "Length of linked_cids:  9\n",
      "{'CID': 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Content': 'Node 14', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qmb45b26ef47ac4c90890a5d777dde81a76a', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmc5a67246ae7de78d5f879d48b7d3fbb8d6', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm7d99d54388e95cbcba31fd904f02d22737', 'Qm3b38ae9a23ca6bf9b905fc773d06a8e014', 'Qm257646aee4ad89efb091b616c783c6c70a'], 'Timestamp': 1737222966.4256382}\n",
      "K =  6\n",
      "Length of linked_cids:  6\n",
      "{'CID': 'Qmf68a3e6d57958f0cc0bb5442b4c52bff7d', 'Content': 'Node 15', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm257646aee4ad89efb091b616c783c6c70a', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmb8696e43681cb65e169a8c5ecbb85c2398'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Content': 'Node 16', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm38ac7d503a770f0a1e8d59b9178a75c04b', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm257646aee4ad89efb091b616c783c6c70a', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qmf68a3e6d57958f0cc0bb5442b4c52bff7d'], 'Timestamp': 1737222966.4256382}\n",
      "K =  6\n",
      "Length of linked_cids:  6\n",
      "{'CID': 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Content': 'Node 17', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmf68a3e6d57958f0cc0bb5442b4c52bff7d', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm03a960d68af36fa27c15232e67bb46fb17'], 'Timestamp': 1737222966.4256382}\n",
      "K =  8\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm53c691cfd56765862ef27d46281a8a061a', 'Content': 'Node 18', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmf68a3e6d57958f0cc0bb5442b4c52bff7d', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm55777cbb83edd5615ad7dca1c01d80de57'], 'Timestamp': 1737222966.4256382}\n",
      "K =  11\n",
      "Length of linked_cids:  8\n",
      "{'CID': 'Qm0ffa1d2d5138aeab682de663f62c14fdc1', 'Content': 'Node 19', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qmf68a3e6d57958f0cc0bb5442b4c52bff7d', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm53c691cfd56765862ef27d46281a8a061a'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm0c4b379fe6ef89be24b4d4e43547557eb8', 'Content': 'Node 20', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm0ffa1d2d5138aeab682de663f62c14fdc1'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Content': 'Node 21', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm0c4b379fe6ef89be24b4d4e43547557eb8'], 'Timestamp': 1737222966.4256382}\n",
      "K =  9\n",
      "Length of linked_cids:  8\n",
      "{'CID': 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Content': 'Node 22', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm0c4b379fe6ef89be24b4d4e43547557eb8', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40'], 'Timestamp': 1737222966.4256382}\n",
      "K =  11\n",
      "Length of linked_cids:  9\n",
      "{'CID': 'Qm85e934698f309c63ba2e6d54c72a41d22c', 'Content': 'Node 23', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qmb8696e43681cb65e169a8c5ecbb85c2398', 'Qm3bc86c60ab0c7e4c9a72c1a3ddcd955e8c', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm0c4b379fe6ef89be24b4d4e43547557eb8', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qmdddc2afccbe1ca810b8741055b823718b4', 'Content': 'Node 24', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm55777cbb83edd5615ad7dca1c01d80de57', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Qm85e934698f309c63ba2e6d54c72a41d22c'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qm048d0f411572b5c223fb65ba0ab4778e13', 'Content': 'Node 25', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm85e934698f309c63ba2e6d54c72a41d22c', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qmdddc2afccbe1ca810b8741055b823718b4'], 'Timestamp': 1737222966.4256382}\n",
      "K =  8\n",
      "Length of linked_cids:  8\n",
      "{'CID': 'Qm69757f4ce921912534eb774152a91c4f7c', 'Content': 'Node 26', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm85e934698f309c63ba2e6d54c72a41d22c', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qmdddc2afccbe1ca810b8741055b823718b4', 'Qm048d0f411572b5c223fb65ba0ab4778e13'], 'Timestamp': 1737222966.4256382}\n",
      "K =  9\n",
      "Length of linked_cids:  9\n",
      "{'CID': 'Qm651dd280f4e6f1fff316e8692133fbe7c5', 'Content': 'Node 27', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm01f5ff498839f0c3f88ebc6d4485e59a40', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qm85e934698f309c63ba2e6d54c72a41d22c', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qmdddc2afccbe1ca810b8741055b823718b4', 'Qm048d0f411572b5c223fb65ba0ab4778e13', 'Qm69757f4ce921912534eb774152a91c4f7c'], 'Timestamp': 1737222966.4256382}\n",
      "K =  9\n",
      "Length of linked_cids:  9\n",
      "{'CID': 'Qm1754444dea84afc43f8e110b65f30bf54c', 'Content': 'Node 28', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm69757f4ce921912534eb774152a91c4f7c', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qm85e934698f309c63ba2e6d54c72a41d22c', 'Qm048d0f411572b5c223fb65ba0ab4778e13', 'Qm24fbe9dc21ffbf1176b019dbb512279fde', 'Qmdddc2afccbe1ca810b8741055b823718b4', 'Qm651dd280f4e6f1fff316e8692133fbe7c5'], 'Timestamp': 1737222966.4256382}\n",
      "K =  7\n",
      "Length of linked_cids:  7\n",
      "{'CID': 'Qma7600328077ae4e23fd685d2a3dadc0b00', 'Content': 'Node 29', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756', 'Qm048d0f411572b5c223fb65ba0ab4778e13', 'Qm651dd280f4e6f1fff316e8692133fbe7c5', 'Qm7e879f6b148f2e4a2ea70dbadd2eb5ad7f', 'Qm69757f4ce921912534eb774152a91c4f7c', 'Qm03a960d68af36fa27c15232e67bb46fb17', 'Qm1754444dea84afc43f8e110b65f30bf54c'], 'Timestamp': 1737222966.4256382}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 30, 'update': 30}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 30, 'store': 30, 'retrieve': 39}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Resetting IPFS from the last test\n",
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 30\n",
    "URL = \"example.com\"\n",
    "Kmin = 5\n",
    "Kmax = 10\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \"+str(i)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = []\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    K = random.randint(Kmin, Kmax)\n",
    "    # Check if the number of linked CIDs is greater than K and add K-1 random linked CIDs\n",
    "    if len(latest_node_linked_cids) > K:\n",
    "        linked_cids.extend(random.sample(latest_node_linked_cids[1:], K-1))\n",
    "    # If the number of linked CIDs is less than K add all the linked CIDs\n",
    "    else:\n",
    "        linked_cids.extend(latest_node_linked_cids[1:])\n",
    "    linked_cids.append(latest_node_cid)\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    print(\"K = \", K+1)\n",
    "    print(\"Length of linked_cids: \", len(linked_cids))\n",
    "    print(node)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 13\n",
      "Can't find node\n",
      "Found node: {'CID': 'Qm8f80bd8bb8fc158e89c4b9c8ad9559a0fa', 'Content': 'Node 1', 'Linked CID(s)': ['Qmc06f910f97a2c73fb6fbde6e3b1e7ce756'], 'Timestamp': 1737222966.4235377}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 28}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index 1\n",
    "    node = ipfs.retrieve(linked_cids[1])\n",
    "    linked_cids = node.get_linked_cids()\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.get_content() == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[1])\n",
    "            linked_cids = node.get_linked_cids()\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "# Output the found node\n",
    "print(f\"Found node: {node}\")\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking to Sequential Exponential (Base K, K an integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2\n",
      "Node 1\n",
      "Node 0\n",
      "Length of linked_cids:  2\n",
      "Node 3\n",
      "Node 2\n",
      "Node 1\n",
      "Length of linked_cids:  3\n",
      "Node 4\n",
      "Node 3\n",
      "Node 2\n",
      "Node 0\n",
      "Length of linked_cids:  3\n",
      "Node 5\n",
      "Node 4\n",
      "Node 3\n",
      "Node 1\n",
      "Length of linked_cids:  4\n",
      "Node 6\n",
      "Node 5\n",
      "Node 4\n",
      "Node 2\n",
      "Length of linked_cids:  4\n",
      "Node 7\n",
      "Node 6\n",
      "Node 5\n",
      "Node 3\n",
      "Node 0\n",
      "Length of linked_cids:  4\n",
      "Node 8\n",
      "Node 7\n",
      "Node 6\n",
      "Node 4\n",
      "Node 0\n",
      "Length of linked_cids:  4\n",
      "Node 9\n",
      "Node 8\n",
      "Node 7\n",
      "Node 5\n",
      "Node 1\n",
      "Length of linked_cids:  5\n",
      "Node 10\n",
      "Node 9\n",
      "Node 8\n",
      "Node 6\n",
      "Node 2\n",
      "Length of linked_cids:  5\n",
      "Node 11\n",
      "Node 10\n",
      "Node 9\n",
      "Node 7\n",
      "Node 3\n",
      "Length of linked_cids:  5\n",
      "Node 12\n",
      "Node 11\n",
      "Node 10\n",
      "Node 8\n",
      "Node 4\n",
      "Length of linked_cids:  5\n",
      "Node 13\n",
      "Node 12\n",
      "Node 11\n",
      "Node 9\n",
      "Node 5\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 14\n",
      "Node 13\n",
      "Node 12\n",
      "Node 10\n",
      "Node 6\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 15\n",
      "Node 14\n",
      "Node 13\n",
      "Node 11\n",
      "Node 7\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 16\n",
      "Node 15\n",
      "Node 14\n",
      "Node 12\n",
      "Node 8\n",
      "Node 0\n",
      "Length of linked_cids:  5\n",
      "Node 17\n",
      "Node 16\n",
      "Node 15\n",
      "Node 13\n",
      "Node 9\n",
      "Node 1\n",
      "Length of linked_cids:  6\n",
      "Node 18\n",
      "Node 17\n",
      "Node 16\n",
      "Node 14\n",
      "Node 10\n",
      "Node 2\n",
      "Length of linked_cids:  6\n",
      "Node 19\n",
      "Node 18\n",
      "Node 17\n",
      "Node 15\n",
      "Node 11\n",
      "Node 3\n",
      "Length of linked_cids:  6\n",
      "Node 20\n",
      "Node 19\n",
      "Node 18\n",
      "Node 16\n",
      "Node 12\n",
      "Node 4\n",
      "Length of linked_cids:  6\n",
      "Node 21\n",
      "Node 20\n",
      "Node 19\n",
      "Node 17\n",
      "Node 13\n",
      "Node 5\n",
      "Length of linked_cids:  6\n",
      "Node 22\n",
      "Node 21\n",
      "Node 20\n",
      "Node 18\n",
      "Node 14\n",
      "Node 6\n",
      "Length of linked_cids:  6\n",
      "Node 23\n",
      "Node 22\n",
      "Node 21\n",
      "Node 19\n",
      "Node 15\n",
      "Node 7\n",
      "Length of linked_cids:  6\n",
      "Node 24\n",
      "Node 23\n",
      "Node 22\n",
      "Node 20\n",
      "Node 16\n",
      "Node 8\n",
      "Length of linked_cids:  6\n",
      "Node 25\n",
      "Node 24\n",
      "Node 23\n",
      "Node 21\n",
      "Node 17\n",
      "Node 9\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 26\n",
      "Node 25\n",
      "Node 24\n",
      "Node 22\n",
      "Node 18\n",
      "Node 10\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 27\n",
      "Node 26\n",
      "Node 25\n",
      "Node 23\n",
      "Node 19\n",
      "Node 11\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 28\n",
      "Node 27\n",
      "Node 26\n",
      "Node 24\n",
      "Node 20\n",
      "Node 12\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Node 29\n",
      "Node 28\n",
      "Node 27\n",
      "Node 25\n",
      "Node 21\n",
      "Node 13\n",
      "Node 0\n",
      "Length of linked_cids:  6\n",
      "Number of operations IPNS performed:\n",
      "{'get': 30, 'update': 30}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 30, 'store': 30, 'retrieve': 146}\n"
     ]
    }
   ],
   "source": [
    "ipfs.reset_data()\n",
    "\n",
    "# Testing parameters\n",
    "NODE_NUM = 30\n",
    "K = 2\n",
    "URL = \"example.com\"\n",
    "\n",
    "# Create and store the first node\n",
    "content = \"Node 0\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "first_node = IPARO(cid=cid, linked_cids=[],\n",
    "                   content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, first_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# Create and store the second node\n",
    "content = \"Node 1\"\n",
    "timestamp = time.time()\n",
    "to_be_hashed = str({\n",
    "    \"content\": content,\n",
    "    \"timestamp\": timestamp\n",
    "})\n",
    "cid = ipfs.hash(to_be_hashed)\n",
    "linked_cids = [ipns.get_cid(URL)]\n",
    "second_node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                    content=content, timestamp=timestamp)\n",
    "ipfs.store(cid, second_node)\n",
    "ipns.update(URL, cid)\n",
    "\n",
    "# To automate creating and adding the remaining nodes\n",
    "for i in range(2, NODE_NUM):\n",
    "    content = \"Node \" + str(i)\n",
    "    print(content)\n",
    "    timestamp = time.time()\n",
    "    to_be_hashed = str({\n",
    "        \"content\": content,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    cid = ipfs.hash(to_be_hashed)\n",
    "    latest_node_cid = ipns.get_cid(URL)\n",
    "    latest_node = ipfs.retrieve(latest_node_cid)\n",
    "    latest_node_linked_cids = latest_node.get_linked_cids()\n",
    "    linked_cids = []\n",
    "\n",
    "    # Link to previous node FIRST\n",
    "    linked_cids.append(latest_node_linked_cids[0])\n",
    "    cids = []\n",
    "\n",
    "    j = 1\n",
    "    # Temp node = latest node CID inserted (before this one). Call that node K-1.\n",
    "    if i == 4:\n",
    "        pass\n",
    "    temp_node = latest_node\n",
    "    print(temp_node.get_content())\n",
    "    done = False\n",
    "    while True:\n",
    "        # Theorem: For any m < len(temp_node_linked_cids), the mth-to-last position of the linked CIDs list will link K^m nodes away from the node.\n",
    "        # Base Case: The previous node always gets assigned the last position (m=0), so the base case holds.\n",
    "        # Inducive Case: Suppose that the property holds for m=k. Then, we need to prove that it holds for m=k+1.\n",
    "        # The start node is K^k nodes away from the most recent node. But if we use the kth position of the linked\n",
    "        # CIDs, and travelled the kth link (K - 1) times, then the CID to be added to the linked CIDs (at the (k+1)th\n",
    "        # position) is K^k + (K-1) * K^k = K*K^k = K^(k+1), which proves the inductive case.\n",
    "        # Therefore, by the Principle of Mathematical Induction, I proved that this theorem holds.\n",
    "        for _ in range(K - 1):\n",
    "            temp_cid = temp_node.get_cid()\n",
    "            temp_node_linked_cids = temp_node.get_linked_cids()\n",
    "            done = j > len(temp_node_linked_cids)\n",
    "            if done:\n",
    "                break\n",
    "            temp_node = ipfs.retrieve(temp_node_linked_cids[-j])\n",
    "        if done:\n",
    "            break\n",
    "        print(temp_node.get_content())\n",
    "        # Ensure no duplicate links\n",
    "        if temp_node.get_cid() not in linked_cids:\n",
    "            cids.append(temp_node.get_cid())\n",
    "        j += 1\n",
    "    cids = list(reversed(cids))\n",
    "    linked_cids.extend(cids)\n",
    "    linked_cids.append(latest_node_cid)\n",
    "\n",
    "    print(\"Length of linked_cids: \", len(linked_cids))\n",
    "    node = IPARO(cid=cid, linked_cids=linked_cids,\n",
    "                 content=content, timestamp=timestamp)\n",
    "    ipfs.store(cid, node)\n",
    "    ipns.update(URL, cid)\n",
    "\n",
    "get_op_counts()  # Output operation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 22\n",
      "Found node: {'CID': 'Qm8ad3cc9dd2f9b51f6b034a738f478f11ac', 'Content': 'Node 22', 'Linked CID(s)': ['Qm126aff12842a9bc50dbdbdbf460181654f', 'Qmf3fd0d4d150c51253551f79294ef6eab61', 'Qm375389864575456cbde778569832f00e90', 'Qmab9f7e5e2dc4cb1cf28a9c6c734563e83c', 'Qm831c533fa4968330bb63faabb24b448d32', 'Qme5685c8c8b572c2a5386b4c532ae767234'], 'Timestamp': 1737246260.5532575}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 24}\n"
     ]
    }
   ],
   "source": [
    "# Reset the operation counts\n",
    "ipfs.reset_counts()\n",
    "ipns.reset_counts()\n",
    "\n",
    "# Pick a random node to search for\n",
    "node_num = random.randint(0, NODE_NUM - 1)\n",
    "target_content = f\"Node {node_num}\"\n",
    "print(f\"Looking for node with content: {target_content}\")\n",
    "\n",
    "# Check if the first node is the desired node then search the other nodes\n",
    "latest_node_cid = ipns.get_cid(URL)\n",
    "node = ipfs.retrieve(latest_node_cid)\n",
    "linked_cids = node.get_linked_cids()\n",
    "first_node_cid = linked_cids[0]\n",
    "first_node = ipfs.retrieve(first_node_cid)\n",
    "if first_node.get_content() == target_content:\n",
    "    print(f\"Found node: {node}\")\n",
    "else:\n",
    "    # run through the rest of the linked cids list to check\n",
    "    for cid in linked_cids:\n",
    "        node = ipfs.retrieve(cid)\n",
    "        if node.get_content() == target_content:\n",
    "            break\n",
    "    # Get the linked cids of the node at index -1 (where the latest index is)\n",
    "    node = ipfs.retrieve(linked_cids[-1])\n",
    "    linked_cids = node.get_linked_cids()\n",
    "    while True:\n",
    "        # Flag to determine if we should exit the while loop\n",
    "        found = False\n",
    "\n",
    "        # Run through the rest of the linked CIDs list to check\n",
    "        for cid in linked_cids[1:]:\n",
    "            node = ipfs.retrieve(cid)\n",
    "            if node.get_content() == target_content:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            print(f\"Found node: {node}\")\n",
    "            break  # Exit the while loop if the node was found\n",
    "\n",
    "        if len(linked_cids) >= 2:\n",
    "            node = ipfs.retrieve(linked_cids[-1])\n",
    "            linked_cids = node.get_linked_cids()\n",
    "            # Output the found node\n",
    "        else:\n",
    "            print('Can\\'t find node')\n",
    "            break\n",
    "\n",
    "get_op_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for node with content: Node 24\n",
      "Can't find node\n",
      "Found node: {'CID': 'Qm3e86b1fea41595c77a61345510bb3503b1', 'Content': 'Node 1', 'Linked CID(s)': ['Qme931ce5daa92fe0ad27cc618145ed41c1b'], 'Timestamp': 1737245623.6878963}\n",
      "Number of operations IPNS performed:\n",
      "{'get': 1, 'update': 0}\n",
      "Number of operations IPFS performed:\n",
      "{'hash': 0, 'store': 0, 'retrieve': 10}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other strategies to be tested"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
